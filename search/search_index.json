{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-the-official-cyberbro-documentation","title":"Welcome to the official Cyberbro Documentation!","text":"<p>Tip</p> <p>Cyberbro is an open-source threat intelligence and indicator analysis platform. Whether you're a new user or a seasoned developer, this documentation will help you get started, configure, and make the most of Cyberbro's features.</p>"},{"location":"#documentation-overview","title":"\ud83d\udcd6 Documentation Overview","text":"<ul> <li> <p>Quick Start &amp; Installation     Get up and running quickly with Docker or manual installation. Learn how to configure API keys and launch Cyberbro.</p> </li> <li> <p>Reload Secrets and Configuration     How to reload or update your configuration and secrets without downtime.</p> </li> <li> <p>API Usage &amp; Engine Names     Explore the Cyberbro API, supported engines, and integration details.</p> </li> <li> <p>Advanced Deployment Options     Customize your deployment with environment variables, Docker Compose, and advanced settings.</p> </li> <li> <p>Upgrade Cyberbro     Step-by-step guide to safely upgrade your Cyberbro instance.</p> </li> </ul>"},{"location":"#engines","title":"\ud83d\udd10 Engines","text":"<ul> <li>Bad ASN Check     Learn how the Bad ASN Check engine works, including its background service, data sources, risk scoring algorithm, and how to use it effectively.</li> </ul>"},{"location":"#integrations","title":"\ud83d\udd17 Integrations","text":"<ul> <li> <p>Cyberbro in KASM Workspaces     Deploy and configure Cyberbro in KASM Workspaces for browser-based access.</p> </li> <li> <p>Cyberbro Browser Extension     Install and use the browser extension for quick indicator analysis.</p> </li> <li> <p>Cyberbro CLI     Use the command-line interface for quick indicator lookups and automation.</p> </li> <li> <p>Use Cyberbro MCP for LLM     Integrate Cyberbro with Model Context Protocol for LLM workflows.</p> </li> </ul>"},{"location":"#api-key-guides","title":"\ud83d\udd11 API Key Guides","text":"<ul> <li>Get AbuseIPDB API Key</li> <li>Get AlienVault API Key</li> <li>Get Crowdstrike API Credentials</li> <li>Get DFIR-Iris API Key</li> <li>Get Google CSE API Key</li> <li>Get Google Safe Browsing API Key</li> <li>Get IPapi API Key</li> <li>Get IPinfo API Key</li> <li>Get MDE (Microsoft Defender for Endpoint) API Credentials</li> <li>Get MISP API Key</li> <li>Get OpenCTI API Key</li> <li>Get Reversing Labs Spectra Analyze API key</li> <li>Get R\u00f6sti API Key</li> <li>Get Shodan API Key</li> <li>Get Spur.us API Key</li> <li>Get ThreatFox API Key</li> <li>Get VirusTotal API Key</li> <li>Get WebScout API Key</li> </ul>"},{"location":"#coding-contribution","title":"\ud83d\udee0\ufe0f Coding &amp; Contribution","text":"<ul> <li>Documentation</li> <li>Coding Style</li> <li>Contributions</li> </ul>"},{"location":"#troubleshooting","title":"\ud83d\udd0e Troubleshooting","text":"<ul> <li>Common Issues</li> </ul>"},{"location":"#community","title":"\ud83c\udf89 Community","text":"<ul> <li>They talk about Cyberbro </li> </ul> <p>For more details, browse the sidebar or use the search. If you need help, check the Cyberbro GitHub repository.</p> <p>Happy analyzing!</p>"},{"location":"api-keys/Get-AbuseIPDB-API-key/","title":"Get AbuseIPDB API Key","text":"<ol> <li>Go to https://www.abuseipdb.com/ and create a free account.</li> <li>Go to https://www.abuseipdb.com/account/api</li> <li>Get your API key.</li> </ol> <p>You can fill the <code>secrets.json</code> accordingly with the variable <code>\"abuseipdb\"</code> or the environment variable <code>ABUSEIPDB</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-AlienVault-API-key/","title":"How to Get AlienVault OTX API Key","text":"<p>AlienVault OTX (Open Threat Exchange) is a collaborative threat intelligence platform. To interact with OTX programmatically, you need an API key. Follow these steps to obtain your API key from the OTX portal.</p>"},{"location":"api-keys/Get-AlienVault-API-key/#steps-to-obtain-an-api-key-for-alienvault-otx","title":"Steps to Obtain an API Key for AlienVault OTX","text":"<ol> <li> <p>Access the OTX Portal:     Open your web browser and go to https://otx.alienvault.com.</p> </li> <li> <p>Log In or Sign Up:     Log in with your existing account credentials.     If you do not have an account, click \"Sign Up\" and follow the instructions to create one.</p> </li> <li> <p>Go to Your Account Settings:     Once logged in, click on your username or avatar in the top-right corner and select \"Settings\" from the dropdown menu.</p> </li> <li> <p>Find the API Key:     In the \"API Key\" section of your settings page, you will see your personal OTX API key.</p> </li> <li> <p>Copy the API Key:     Copy your API key and store it securely. You will need this key to authenticate your API requests.</p> </li> </ol> <p>Note</p> <p>Keep your API key confidential. If you believe your key has been compromised, you can regenerate it from the same settings page.</p> <p>Fill the <code>secrets.json</code> file with <code>\"alienvault\"</code> or use the environment variable <code>ALIENVAULT</code> in your configuration or docker-compose file.</p>"},{"location":"api-keys/Get-Crowdstrike-API-Credentials/","title":"Get Crowdstrike API Credentials","text":"<p>Info</p> <p>Requirements: Crowdstrike is a paid service, you must have an account to get API keys. You will need an account with administrative permissions to create API credentials.  </p> <p>Falcon Insight XDR is required to access the API (Device Count). Falcon Intelligence or Falcon Intelligence Premium is required to access the API (CTI Data).</p> <p>Note</p> <p>You can use Cyberbro with Falcon Insight XDR only but the CTI data won't be displayed, you will just have Device Count (on how many devices the observable was seen).</p> <p>To interact with the Crowdstrike API, you need to obtain the following credentials:</p> <ul> <li>Client ID (<code>\"crowdstrike_client_id\"</code> in <code>secrets.json</code> or <code>CROWDSTRIKE_CLIENT_ID</code> environment variable).</li> <li>Client Secret (<code>\"crowdstrike_client_secret\"</code> in <code>secrets.json</code> or <code>CROWDSTRIKE_CLIENT_SECRET</code> environment variable).</li> </ul> <p>Additionally, you need to assign the appropriate API permissions to your application to interact with Indicators of Compromise (IOC) and Intel.</p>"},{"location":"api-keys/Get-Crowdstrike-API-Credentials/#steps-to-obtain-api-credentials","title":"Steps to Obtain API Credentials","text":""},{"location":"api-keys/Get-Crowdstrike-API-Credentials/#1-log-in-to-the-crowdstrike-falcon-console","title":"1. Log in to the Crowdstrike Falcon Console","text":"<ol> <li>Go to the Crowdstrike Falcon Console.</li> <li>Log in with your credentials.</li> </ol>"},{"location":"api-keys/Get-Crowdstrike-API-Credentials/#2-navigate-to-api-clients-and-keys","title":"2. Navigate to API Clients and Keys","text":"<ol> <li>In the left-hand menu, navigate to Support and resources API Clients and Keys</li> <li>Click Create API client.</li> </ol>"},{"location":"api-keys/Get-Crowdstrike-API-Credentials/#3-create-a-new-api-client","title":"3. Create a New API Client","text":"<ol> <li>Enter a name and description for your API client.</li> <li> <p>Under Scope, select the following permissions:</p> <ul> <li>IOC Management - Read</li> <li>IOCs (Indicators of Compromise) - Read</li> <li>Indicators (Falcon Intelligence) - Read</li> <li>Actors (Falcon Intelligence) - Read</li> <li>Malware Families (Falcon Intelligence) - Read</li> <li>Reports (Falcon Intelligence) - Read</li> </ul> </li> <li> <p>Click Create.</p> </li> </ol>"},{"location":"api-keys/Get-Crowdstrike-API-Credentials/#4-obtain-client-id-and-client-secret","title":"4. Obtain Client ID and Client Secret","text":"<ol> <li>After creating the API client, you will be shown the Client ID and Client Secret.</li> <li>Copy these values and store them securely. </li> </ol> <p>Warning</p> <p>Make sure to copy the Client Secret now as it will not be shown again.</p>"},{"location":"api-keys/Get-Crowdstrike-API-Credentials/#summary","title":"Summary","text":"<p>You now have the Client ID and Client Secret required to authenticate with the Crowdstrike API. Additionally, you have assigned the necessary permissions to interact with Indicators of Compromise (IOC) and Intel.</p> <p>For more information, consult the official documentation.</p>"},{"location":"api-keys/Get-Crowdstrike-API-Credentials/#configure-falcon-url","title":"Configure Falcon URL","text":"<p>Tip</p> <p>To configure the Falcon link (clickable in the GUI), users may utilize the optional <code>\"crowdstrike_falcon_base_url\": \"https://falcon.crowdstrike.com\"</code> setting in <code>secrets.json</code> or the <code>CROWDSTRIKE_FALCON_BASE_URL</code> environment variable. By default, this variable is set to \"https://falcon.crowdstrike.com\". For instance, those operating within the US2 region should specify the prefix as \"https://falcon.us-2.crowdstrike.com\".</p>"},{"location":"api-keys/Get-Crowdstrike-API-Credentials/#screenshots","title":"Screenshots","text":""},{"location":"api-keys/Get-DFIR-IRIS-API-key/","title":"Get DFIR Iris API Key","text":""},{"location":"api-keys/Get-DFIR-IRIS-API-key/#how-to-get-a-dfir-iris-api-key","title":"How to get a DFIR IRIS API key","text":"<p>DFIR-IRIS is an open-source platform for incident response case management and provides a way to manage cases, assets, indicators and timelines.</p>"},{"location":"api-keys/Get-DFIR-IRIS-API-key/#steps-to-obtain-a-api-key-for-the-demo-instance-of-dfir-iris","title":"Steps to obtain a API key for the demo instance of DFIR-IRIS","text":"<ol> <li> <p>Read the Welcome page about how to access the demo instance:    Browse to DFIR IRIS demo instance and select an account to use.    The page show a list of accounts that can be used, and has an Access Iris button to get to the demo instance.</p> </li> <li> <p>Log in    Log in with the account and password selected from the previous step.</p> </li> <li> <p>Get the API key    Click on the account icon in the top left sidebar and select Settings.</p> </li> <li> <p>Copy the API key    The user settings page will have an API key that can be copied. The key can be renewed and by that disabling any previous key. The key will hold the same permissions as the user.</p> </li> <li> <p>Optional, create new account    It is possible to log in with an administrator account and then create a new user under the Advanced/Access Control tab. Add a new user with a password and assign the user to customers and a role. Then get the API key in the same was as in the previous step.</p> </li> <li> <p>Optional, use a dedicated service account    To have a dedicated service account that can only do global search, you will first need to add a group with the <code>search_across_cases</code> permissions. Create a new group and give it only that permission. When creating a new user, check the <code>Use as service account</code> and assign the group to the user.</p> </li> </ol> <p>Fill out the <code>secrets.json</code> file accordingly with <code>\"dfir_iris_url\"</code> and <code>\"dfir_iris_api_key\"</code> or use the environment variables <code>DFIR_IRIS_URL</code> and <code>DFIR_IRIS_API_KEY</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-Google-CSE-API-key/","title":"Get Google CSE API Key","text":"<p>Google Custom Search Engine (CSE) will help you to get Google results for Cyberbro analysis.</p> <ol> <li>Visit Programmable Search Engine page</li> <li>Click on \"Get a Key\" to create or use an existing project and enable the Custom Search API.</li> <li>Copy the API key and the Custom Search Engine ID (CX) from your CSE control panel.</li> </ol> <p>Info</p> <p>Google Custom Search API has usage limits. The free tier allows for 100 search queries per day. For higher usage, consider enabling billing on your Google Cloud project ($5 per 1000 queries).</p> <p>You can fill the <code>secrets.json</code> accordingly with the variables <code>\"google_cse_key\"</code> and <code>\"google_cse_cx\"</code>, or use the environment variables <code>GOOGLE_CSE_KEY</code> and <code>GOOGLE_CSE_CX</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-Google-Safe-Browing-API-key/","title":"Get Google Safe Browsing API Key","text":"<ol> <li>Visit Google Cloud Console: Go to the Google Cloud Console.</li> <li>Create a New Project: Click on the project dropdown and select \"New Project\". Name your project and click \"Create\".</li> <li>Enable Safe Browsing API: In the left sidebar, navigate to \"APIs &amp; Services\" &gt; \"Library\". Search for \"Safe Browsing API\" and click on it. Then, click \"Enable\".</li> <li>Create Credentials: Go to \"APIs &amp; Services\" &gt; \"Credentials\". Click on \"Create Credentials\" and select \"API Key\". Your API key will be generated and displayed.</li> </ol> <p>You can fill the <code>secrets.json</code> accordingly with the variable <code>\"google_safe_browsing\"</code> or the environment variable <code>GOOGLE_SAFE_BROWSING</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-IPapi-API-key/","title":"Get IPapi API Key","text":"<ol> <li>Go to https://ipapi.is/ </li> <li>Sign up for a free account (if you don't have one already).  </li> <li>Go to https://ipapi.is/app/home and copy your API key.</li> </ol> <p>You can fill the <code>secrets.json</code> accordingly with the variable <code>ipapi</code> or the environment variable <code>IPAPI</code> in your custom docker-compose file.</p> <p>Info</p> <p>The free tier allows up to 1,000 requests per day. While it can be used without an API key, having one increases your rate limit.</p>"},{"location":"api-keys/Get-IPinfo-API-key/","title":"Get IPinfo API Key","text":"<ol> <li>Create a free account on https://ipinfo.io/</li> <li>Go to https://ipinfo.io/account/token</li> <li>Get your token.</li> </ol> <p>You can fill the <code>secrets.json</code> accordingly with the variable <code>ipinfo</code> or the environment variable <code>IPINFO</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/","title":"Get MDE (Microsoft Defender for Endpoint) API Credentials","text":"<p>Info</p> <p>Requirements: Microsoft Defender for Endpoint is a paid service, you must have a tenant to get API keys. You will need an Azure Global Admin to help you.</p> <p>To interact with the Microsoft Defender for Endpoint API, you need to obtain the following credentials:</p> <ul> <li>Tenant ID (<code>\"mde_tenant_id\"</code> in <code>secrets.json</code> or <code>MDE_TENANT_ID</code> environment variable).</li> <li>Client ID (<code>\"mde_client_id\"</code> in <code>secrets.json</code> or <code>MDE_CLIENT_ID</code> environment variable).</li> <li>Client Secret (<code>\"mde_client_secret\"</code> in <code>secrets.json</code> or <code>MDE_CLIENT_SECRET</code> environment variable).</li> </ul> <p>Additionally, you need to assign the appropriate API permissions to your application to check IP addresses, hashes, domains, and URLs.</p>"},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#steps-to-obtain-api-credentials","title":"Steps to Obtain API Credentials","text":""},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#1-register-an-application-in-azure-ad","title":"1. Register an Application in Azure AD","text":"<ol> <li>Go to the Azure Portal.</li> <li>Navigate to Entra ID &gt; App registrations.</li> <li>Click New registration.</li> <li>Enter a name for your application.</li> <li>Select the supported account types.</li> <li>Click Register.</li> </ol>"},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#2-obtain-tenant-id-and-client-id","title":"2. Obtain Tenant ID and Client ID","text":"<ol> <li>After registering the application, you will be redirected to the application's overview page.</li> <li>Copy the Application (client) ID. This is your Client ID.</li> <li>Copy the Directory (tenant) ID. This is your Tenant ID.</li> </ol>"},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#3-create-a-client-secret","title":"3. Create a Client Secret","text":"<ol> <li>In the application's overview page, navigate to Certificates &amp; secrets.</li> <li>Under Client secrets, click New client secret.</li> <li>Add a description and set an expiration period.</li> <li>Click Add.</li> <li>Copy the value of the client secret. This is your Client Secret. Note: Make sure to copy it now as it will not be shown again.</li> </ol>"},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#assign-api-permissions","title":"Assign API Permissions","text":""},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#1-navigate-to-api-permissions","title":"1. Navigate to API Permissions","text":"<ol> <li>In the application's overview page, navigate to API permissions.</li> <li>Click Add a permission.</li> </ol>"},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#2-add-microsoft-defender-for-endpoint-permissions","title":"2. Add Microsoft Defender for Endpoint Permissions","text":"<ol> <li>Select APIs my organization uses.</li> <li>Search for Microsoft Defender for Endpoint.</li> <li>Select Application permissions.</li> <li>Add the following permissions:<ul> <li><code>File.Read.All</code></li> <li><code>Ip.Read.All</code></li> <li><code>Url.Read.All</code></li> </ul> </li> </ol> <p>Note</p> <p>Ensure that these permissions are added under the Application permissions section, not Delegated permissions.</p> <ol> <li>Click Add permissions.</li> </ol>"},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#3-grant-admin-consent","title":"3. Grant Admin Consent","text":"<ol> <li>After adding the permissions, click Grant admin consent for [Your Organization].</li> <li>Confirm by clicking Yes.</li> </ol>"},{"location":"api-keys/Get-MDE-%28Microsoft-Defender-for-Endpoint%29-API-credentials/#summary","title":"Summary","text":"<p>You now have the Tenant ID, Client ID, and Client Secret required to authenticate with the Microsoft Defender for Endpoint API. Additionally, you have assigned the necessary permissions to check IP addresses, hashes, domains, and URLs.</p> <p>For more information, consult the official documentation.</p>"},{"location":"api-keys/Get-MISP-API-key/","title":"Get MISP API Key","text":""},{"location":"api-keys/Get-MISP-API-key/#how-to-get-misp-api-key","title":"How to Get MISP API Key","text":"<p>MISP (Malware Information Sharing Platform &amp; Threat Sharing) is an open-source threat intelligence platform. To interact with MISP programmatically, you need an API key. Here is a step-by-step guide on how to obtain an API key from your MISP instance.</p>"},{"location":"api-keys/Get-MISP-API-key/#steps-to-obtain-an-api-key-for-misp","title":"Steps to Obtain an API Key for MISP","text":"<ol> <li> <p>Access Your MISP Instance:     Open your web browser and navigate to the URL of your MISP instance.</p> </li> <li> <p>Log In:     Enter your credentials to log in to your MISP account.     If you do not have an account, contact your MISP administrator to request access.</p> </li> <li> <p>Navigate to Your Profile:     Once logged in, click on your username in the top-right corner and select \"My Profile\" from the dropdown menu.</p> </li> <li> <p>Locate the Auth Key:     On your profile page, find the \"Authkey\" section. This is your personal API key for accessing the MISP API.</p> </li> <li> <p>Copy the API Key:     Copy your API key and store it securely. You will need this key to authenticate your API requests.</p> </li> </ol> <p>Note</p> <p>Keep your API key confidential. If you believe your key has been compromised, you can regenerate it from the same profile page.</p> <p>Fill the <code>secrets.json</code> file with <code>\"misp_url\"</code> and <code>\"misp_api_key\"</code> or use the environment variables <code>MISP_URL</code> and <code>MISP_API_KEY</code> in your configuration or docker-compose file.</p>"},{"location":"api-keys/Get-OpenCTI-API-key/","title":"Get OpenCTI API Key","text":""},{"location":"api-keys/Get-OpenCTI-API-key/#how-to-get-opencti-api-key","title":"How to Get OpenCTI API Key","text":"<p>OpenCTI is an open-source platform that provides a powerful and flexible way to manage cyber threat intelligence. To interact with OpenCTI programmatically, you need an API key. Here is a step-by-step guide on how to obtain an API key from the OpenCTI demo instance.</p>"},{"location":"api-keys/Get-OpenCTI-API-key/#steps-to-obtain-an-api-key-for-the-demo-of-opencti","title":"Steps to Obtain an API Key for the demo of OpenCTI","text":"<ol> <li> <p>Access the Demo Instance (or your instance):     Open your web browser and navigate to the OpenCTI demo instance at https://demo.opencti.io.</p> </li> <li> <p>Log In:     If you already have an account, log in using your credentials.     If you do not have an account, you will need to register for one.</p> </li> <li> <p>Navigate to the Settings:     Once logged in, click on your profile icon in the top-right corner of the screen and select \"Profile\" from the dropdown menu.     Or go to https://demo.opencti.io/dashboard/profile/me</p> </li> <li> <p>API Keys Section:     In the profile page, find and click on the \"API\" section. This section allows you to manage your API keys.</p> </li> <li> <p>Copy the API Key:     Copy this key and store it securely, as you will need it to authenticate your API requests.</p> </li> </ol> <p>Note</p> <p>On the demo instance, the key will be regenerated every 24 hours. If you are using OpenCTI in a production environment, you can manage your API keys more securely.</p> <p>Fill the <code>secrets.json</code> file accordingly with <code>\"opencti_url\"</code> and <code>\"opencti_api_key\"</code> or use the environment variables <code>OPENCTI_URL</code> and <code>OPENCTI_API_KEY</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-ReversingLabs-Spectra-API-key/","title":"Get Reversing Labs Spectra Analyze API Key","text":"<p>Info</p> <p>Requirements: Reversing Labs Spectra Analyze is a paid service that requires a subscription.  </p> <p>The Spectra Analyze service is also different from the Reversing Labs Spectra Intelligence service. This module only covers the Spectra Analyze product. You will need an account that has read-only permissions to the API to use this service.  </p> <p>Reversing Labs Spectra Analyze</p>"},{"location":"api-keys/Get-ReversingLabs-Spectra-API-key/#steps-to-use-reversing-labs-spectra-analyze","title":"Steps to use Reversing Labs Spectra Analyze","text":"<ol> <li>Create a separate user for this or use your own account in the Reversing Labs Dashboard.</li> <li>In the Dashboard, click on the Help/API docs to get to the Swagger interface.</li> <li>In the first entry, Admin, click on the Try it out. Enter  your username and password and choose Execute. A token will be returned that is to be used with Cyberbro.</li> <li>Add this value together with the custom URL for the Reversing Labs Spectra Analyse to either the <code>secrets.json</code> or the <code>.env</code> file.</li> </ol> <p>You need to fill in the <code>secrets.json</code> accordingly with the variable <code>\"rl_analyze_api_key\"</code> and <code>\"rl_analyze_url\"</code> or the environment variables <code>RL_ANALYZE_API_KEY</code> and <code>RL_ANALYZE_URL</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-ReversingLabs-Spectra-API-key/#support","title":"Support","text":"<p>Documentation for how to create a separate user and/or obtaining an API key is in the Spectra Analyze officiell documentation. It is laid out in detail in tokens for user access and in Administrator tokens for administrators.</p>"},{"location":"api-keys/Get-Rosti-API-key/","title":"Get R\u00f6sti API Key","text":"<p>R\u00f6sti (Repackaged Open Source Threat Intelligence) provides threat intelligence IOC search via its API. Follow these steps to obtain an API key.</p> <ol> <li> <p>Visit the R\u00f6sti API portal: </p> <ul> <li>Go to https://rosti.bin.re/api.</li> </ul> </li> <li> <p>Create an account or sign in: </p> <ul> <li>Register if you do not already have access, then log in.</li> </ul> </li> <li> <p>Generate an API key: </p> <ul> <li>In the portal, create a new API key/token. Copy the value and store it securely.</li> </ul> </li> <li> <p>Add the key to Cyberbro: </p> <ul> <li>Update <code>secrets.json</code> with the <code>\"rosti_api_key\"</code> field, or  </li> <li>Export it as an environment variable <code>ROSTI_API_KEY</code>, or  </li> <li>Set it in the <code>.env</code> file using <code>ROSTI_API_KEY=your_key</code>.  </li> </ul> </li> </ol> <p>Note</p> <p>Keep your R\u00f6sti API key confidential. Rotate it immediately if you suspect exposure.</p>"},{"location":"api-keys/Get-Shodan-API-key/","title":"Get Shodan API Key","text":"<ol> <li>Create a free account on https://shodan.io</li> <li>Go to https://account.shodan.io/</li> <li>Beside API key, select \"show\", and get your API key.</li> </ol> <p>You can fill the <code>secrets.json</code> accordingly with the variable <code>\"shodan\"</code> or the environment variable <code>SHODAN</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-Spur-Us-API-key/","title":"How to Get Spur.us Token","text":"<p>Spur.us is a paid service that provides various tools and APIs for cybersecurity professionals. Unlike some services, Spur.us does not provide free API keys. However, they offer a free access to the website to verify IP addresses. Just like: https://spur.us/context/1.1.1.1 (behind captcha).</p>"},{"location":"api-keys/Get-Spur-Us-API-key/#steps-to-retrieve-the-spurus-url","title":"Steps to Retrieve the Spur.us URL","text":"<ol> <li> <p>Access the Spur.us Portal:     Open your web browser and go to https://spur.us.</p> </li> <li> <p>Log In or Sign Up:     Log in with your existing account credentials.     If you do not have an account, click \"Sign Up\" and follow the instructions to create one.</p> </li> <li> <p>Navigate to the Dashboard:     Once logged in, you will be directed to your dashboard. From here, you can access the services provided by Spur.us and get your API key (paid subscription required).</p> </li> </ol> <p>Note</p> <p>Ensure that you comply with Spur.us's terms of service when using their platform. If you encounter issues, contact their support team for assistance.</p> <p>Fill the <code>secrets.json</code> file with <code>\"spur_us\"</code> or use the environment variable <code>SPUR_US</code> in your configuration or docker-compose file.</p> <p>Warning</p> <p>If you don't have API key, only the result URL will be displayed with the note \"Unknown - Behind Captcha\" in Cyberbro. You'll then have to click on the link and complete the CAPTCHA to access the information. There is no API free tier available.</p>"},{"location":"api-keys/Get-ThreatFox-API-key/","title":"Get ThreatFox API Key","text":"<p>To use the ThreatFox API, you need to generate an Auth Key. Follow these steps:</p> <ol> <li>Go to https://auth.abuse.ch/.</li> <li>Log in to your account. If you don\u2019t have one, register for free.</li> <li>Navigate to your profile page.</li> <li>Find the \"Auth Key\" section.</li> <li>Click Generate Auth Key.</li> <li>Copy and securely store your new API key.</li> </ol> <p>You can fill the <code>secrets.json</code> accordingly with the variable <code>\"threatfox\"</code> or the environment variable <code>THREATFOX</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-ThreatFox-API-key/#terms-of-service","title":"Terms of Service","text":"<p>By using ThreatFox and its services, you agree to the following:</p> <ul> <li>All datasets offered by ThreatFox can be used for both commercial and non-commercial purposes without any limitations (CC0 license).</li> <li>Any data offered by ThreatFox is provided \"as is\" on a best-effort basis.</li> </ul> <p>For more details, visit the ThreatFox Terms of Service.</p>"},{"location":"api-keys/Get-VirusTotal-API-key/","title":"Get VirusTotal API Key","text":"<ol> <li>Create a free account on VirusTotal.</li> <li>Go to https://www.virustotal.com/gui/user/username/apikey (replace <code>username</code> with your actual username).</li> <li>Get your token.</li> </ol> <p>Info</p> <p>You are limited to 500 queries a day with the free VT API.</p> <p>You can fill the <code>secrets.json</code> accordingly with the variable <code>virustotal</code> or the environment variable <code>VIRUSTOTAL</code> in your custom docker-compose file.</p>"},{"location":"api-keys/Get-WebScout-API-key/","title":"How to Get a WebScout API Key","text":"<p>To use the WebScout API, you need to obtain an API key. Follow these steps to get your API key:</p>"},{"location":"api-keys/Get-WebScout-API-key/#step-1-sign-up-for-a-webscout-account","title":"Step 1: Sign Up for a WebScout Account","text":"<ol> <li>Visit the WebScout website.</li> <li>Click on the \"Sign Up\" button.</li> <li>Fill in the required details and complete the registration process.</li> </ol>"},{"location":"api-keys/Get-WebScout-API-key/#step-2-log-in-to-your-account","title":"Step 2: Log In to Your Account","text":"<ol> <li>Go to the WebScout login page.</li> <li>Enter your credentials and log in to your account.</li> </ol>"},{"location":"api-keys/Get-WebScout-API-key/#step-3-generate-your-api-key","title":"Step 3: Generate Your API Key","text":"<ol> <li>In the API section, go to API Keys.</li> <li>Click on the \"Generate API Key\" button.</li> <li>Your new API key will be displayed. Make sure to copy and store it securely.</li> </ol> <p>Use it with Cyberbro by using <code>\"webscout\"</code> variable in <code>secrets.json</code> file or <code>WEBSCOUT</code> environment variable.</p>"},{"location":"community/They-talk-about-Cyberbro/","title":"They talk about Cyberbro","text":""},{"location":"community/They-talk-about-Cyberbro/#some-articles-and-posts-about-cyberbro","title":"Some articles and posts about Cyberbro","text":"<ul> <li>Cyberbro - L'Analyse d'IoC facile et en Open Source (Korben.info, Feb 4, 2026)</li> <li>Cyberbro: Practical helper for Indicators of Compromise (heise.de, Jun 2, 2025)</li> <li>Cyberbro: Open source tool extracts IOCs and checks their reputation (all-about-it.blog, May 26, 2025)</li> <li>OSINT Insider Issue #5: Network/Internet (osintinsider.com, May 20, 2024)</li> <li>Cyberbro: Simplify IOC analysis and get CTI insights (meterpreter.org, Mar 14, 2025)</li> <li>14 Amazing Open Source Projects (Medium, Feb 13, 2025)</li> <li>Open source cybersecurity tools you can use for free (Help Net Security, Jan 27, 2025)</li> <li>Cyberbro (Kali Linux Tutorials, Jan 25, 2025)</li> <li>Cyberbro: Open source tool to extract IOCs and check reputation (Help Net Security, Jan 7, 2025)</li> </ul>"},{"location":"contribute/Coding-Style/","title":"Coding Style Policy","text":"<p>This document outlines the coding style and quality guidelines for this project. Adhering to these standards ensures consistency, readability, and security across the codebase.</p>"},{"location":"contribute/Coding-Style/#general-formatting","title":"General Formatting","text":"<ul> <li>Line Length: Limit all lines to a maximum of 100 characters.</li> <li>Indentation: Use 4 spaces per indentation level. Tabs are not allowed.</li> <li>String Quotes: Use double quotes (<code>\"</code>) for all strings.</li> <li>Line Endings: Use <code>LF</code> line endings for cross-platform compatibility.</li> </ul> <p>Formatting is enforced to align with Black conventions, including the use of spaces for indentation and double quotes for strings.</p>"},{"location":"contribute/Coding-Style/#linting-and-static-analysis","title":"Linting and Static Analysis","text":"<p>We use Ruff as the primary linter, configured via <code>.ruff.toml</code>, to enforce the following rules:</p> <ul> <li>Pycodestyle Errors (<code>E</code>): Enforce PEP 8 style guidelines.</li> <li>Pyflakes (<code>F</code>): Detect unused imports, variables, and other common issues.</li> <li>Pywicked (<code>W</code>): Additional style checks.</li> <li>Flake8-Bugbear (<code>B</code>): Catch potential bugs and design issues.</li> <li>Flake8-Comprehensions (<code>C4</code>): Improve list, set, and dictionary comprehensions.</li> <li>Isort (<code>I</code>): Ensure imports are sorted and organized.</li> <li>PEP8-Naming (<code>N</code>): Enforce consistent naming conventions.</li> <li>Flake8-Pygments (<code>PGH</code>): Highlight syntax issues.</li> <li>Flake8-Pytest-Helper (<code>PTH</code>): Enforce pytest-specific best practices.</li> <li>Flake8-Return (<code>RET</code>): Ensure consistent return statements (except <code>RET501</code> which is ignored).</li> <li>Ruff-Specific Rules (<code>RUF</code>): Additional rules specific to Ruff.</li> <li>Flake8-Simplify (<code>SIM</code>): Simplify redundant code patterns.</li> <li>Flake8-Pyupgrade (<code>UP</code>): Modernize Python syntax.</li> <li>Flake8-2020 (<code>YTT</code>): Handle Python 2/3 compatibility issues.</li> </ul>"},{"location":"contribute/Coding-Style/#exclusions","title":"Exclusions","text":"<p>The following directories are excluded from linting and static analysis:</p> <ul> <li><code>tests/**</code></li> <li><code>__pycache__/**</code></li> <li><code>docs/</code></li> <li><code>migrations/</code></li> </ul>"},{"location":"contribute/Coding-Style/#security-scanning","title":"Security Scanning","text":"<p>We use Bandit for static application security testing (SAST), configured via <code>.bandit.yml</code>. Bandit is set up to:</p> <ul> <li>Skip specific tests: <code>B101</code> (assert_used), <code>B113</code> (request_without_timeout)</li> <li>Exclude directories: <code>tests/</code>, <code>docs/</code>, <code>migrations/</code></li> <li>Only scan <code>.py</code> files</li> </ul>"},{"location":"contribute/Coding-Style/#pre-commit-hooks","title":"Pre-Commit Hooks","text":"<p>Automated checks are enforced using pre-commit, configured in <code>.pre-commit-config.yaml</code>. The following hooks are enabled:</p> <ul> <li>trailing-whitespace: Remove trailing whitespace</li> <li>end-of-file-fixer: Ensure files end with a newline</li> <li>check-yaml: Validate YAML files</li> <li>ruff: Lint Python files with Ruff (auto-fix enabled)</li> <li>ruff-format: Format Python files with Ruff</li> <li>bandit: Run Bandit for security checks</li> </ul> <p>Some files and directories (e.g., <code>tests/</code>, <code>__version__.py</code>) are excluded from pre-commit checks.</p>"},{"location":"contribute/Coding-Style/#setup-instructions","title":"Setup Instructions","text":"<ol> <li> <p>Install development dependencies: (make sure you have a venv activated)</p> <pre><code>pip install -r requirements-dev.txt\n</code></pre> </li> <li> <p>Install pre-commit hooks:</p> <pre><code>pre-commit install\n</code></pre> <p>This ensures that Ruff, Bandit, and other checks run automatically on staged files before each commit.</p> </li> <li> <p>Run all pre-commit hooks manually (optional):</p> <pre><code>pre-commit run --all-files\n</code></pre> </li> </ol>"},{"location":"contribute/Coding-Style/#references","title":"References","text":"<ul> <li>Ruff pre-commit integration</li> <li>Bandit documentation</li> <li>pre-commit documentation</li> </ul> <p>By following these guidelines and using the provided tooling, we ensure our codebase remains clean, consistent, and secure.</p>"},{"location":"contribute/Contributions/","title":"Contributions &amp; Community","text":"<p>For details on contributing, community standards, and licensing, see:</p> <ul> <li>Contributing Guidelines</li> <li>Code of Conduct</li> <li>Roadmap</li> <li>License</li> </ul>"},{"location":"contribute/Contributions/#checklist-when-adding-a-new-engine","title":"Checklist when adding a new engine","text":""},{"location":"contribute/Contributions/#engine-implementation","title":"Engine Implementation","text":"<ul> <li>Make sure the engine is added to <code>engines/engine_name.py</code> (use <code>engines/abuseipdb.py</code> as a template).</li> <li>Make sure the engine is added to <code>engines/__init__.py</code>.</li> <li>Make sure that your engine config/secret variable (if relevant) is added to <code>utils/config.py</code>.</li> </ul>"},{"location":"contribute/Contributions/#configuration-secrets","title":"Configuration &amp; Secrets","text":"<ul> <li>Make sure any API key or configuration needed for the engine is added to <code>secrets_sample.json</code> and <code>.env.sample</code>.</li> <li>Make sure you can save secrets using the <code>config.html</code> page.</li> <li>Make sure that the templating of variables in <code>docker-compose.yml</code> is correct.</li> </ul>"},{"location":"contribute/Contributions/#ui-frontend","title":"UI &amp; Frontend","text":"<ul> <li>Make sure the engine result can be copied to clipboard using the GUI in <code>static/format_results.js</code>.</li> <li>Make sure every template in <code>templates/</code> has corresponding engine result template in <code>templates/engines_layouts/</code> - <code>engine_card.html</code> and <code>engine_table.html</code>.</li> <li>Make sure the engine is added in <code>display_cards.html</code> and <code>display_table.html</code>.</li> <li>Make sure the engine is in the GUI form <code>index.html</code> with relevant description - alphabetic order.</li> <li>Make sure the engine is usable in the graph view in <code>graph.html</code>.</li> </ul>"},{"location":"contribute/Contributions/#documentation","title":"Documentation","text":"<ul> <li>Make sure the engine is documented in <code>docs/api-keys/Get-Engine-API-key.md</code> if relevant.</li> <li>Make sure to add the link to the API key guide in <code>docs/index.md</code> if relevant.</li> <li>Make sure the engine is documented in <code>docs/quick-start/API-usage-and-engine-names.md</code>.</li> <li>Make sure to add the page to the sidebar in <code>mkdocs.yml</code>.</li> <li>Make sure the engine is documented in <code>docs/quick-start/Quick-start-&amp;-Installation.md</code> in the <code>secrets.json</code> example.</li> <li>Make sure to add any environment variable needed to <code>docs/quick-start/Advanced-options-for-deployment.md</code> in the <code>docker compose</code> example.</li> <li>Make sure to add references in the README.md (secrets.json example and URL of the new engine in the \"API and third-party services\" section).</li> </ul> <p>Note: if you use an LLM to code, just make sure to use this list as a checklist to verify everything is covered (if something is missing, add it!).</p>"},{"location":"contribute/Documentation/","title":"Documentation Deployment Workflow","text":"<p>This GitHub Actions workflow (<code>deploy-docs.yml</code>) automates the deployment of your documentation site using MkDocs Material.</p> <p>Tip</p> <p>Why use MkDocs Material? Everyone can now easily contribute to the documentation, and it provides a clean, modern look with built-in search functionality.</p>"},{"location":"contribute/Documentation/#how-it-works","title":"How it works","text":"<ul> <li>Trigger: Runs automatically on every push to the <code>main</code> branch.</li> <li>Build &amp; Deploy: Installs MkDocs Material, builds the documentation, and deploys it to the <code>gh-pages</code> branch, which is used by GitHub Pages to serve your site.</li> </ul>"},{"location":"contribute/Documentation/#local-development","title":"Local Development","text":"<p>To preview your documentation locally before pushing changes:</p> <ol> <li>Ensure you have Python installed.</li> <li>Install MkDocs Material:     <pre><code>pip install -r requirements-doc.txt\n</code></pre></li> <li>Serve the documentation locally:     <pre><code>mkdocs serve\n</code></pre>     This will start a local server (usually at http://127.0.0.1:8000/) where you can view your docs.</li> </ol>"},{"location":"contribute/Documentation/#requirements","title":"Requirements","text":"<ul> <li>Your documentation source files should be present (typically in a <code>docs/</code> directory).</li> <li>The <code>mkdocs.yml</code> configuration file should be present at the root of your repository.</li> <li>The workflow will deploy the built site to the <code>gh-pages</code> branch automatically; you do not need to manually push to this branch.</li> </ul> <p>For more details, see the MkDocs Material documentation.</p>"},{"location":"engines/Bad-ASN-Check-Engine/","title":"Bad ASN Check","text":""},{"location":"engines/Bad-ASN-Check-Engine/#overview","title":"Overview","text":"<p>The Bad ASN Check engine is a free, no-API-key-required security feature that identifies malicious Autonomous System Numbers (ASNs) associated with IP addresses. It checks if an IP's ASN is listed in known malicious ASN databases and provides risk scoring to help assess the threat level.</p> <p>This engine is particularly useful for:</p> <ul> <li>VPN and Proxy Detection: Identifies ASNs commonly used by VPN services and anonymization networks</li> <li>Malicious Infrastructure Detection: Detects ASNs associated with spam, malware distribution, and other malicious activities</li> <li>Risk Assessment: Provides a calculated risk score (0-100) based on multiple factors</li> <li>Legitimate Provider Abuse Detection: Distinguishes between inherently malicious ASNs and legitimate cloud/hosting providers that may be abused</li> </ul> <p>No API Key Required</p> <p>This engine is completely free and requires no API key. It works by maintaining a local cache of malicious ASN lists.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#how-it-works","title":"How It Works","text":""},{"location":"engines/Bad-ASN-Check-Engine/#1-asn-extraction","title":"1. ASN Extraction","text":"<p>The Bad ASN engine requires ASN information from other IP geolocation engines. It extracts ASN data from:</p> <ul> <li>ipapi (recommended - most reliable)</li> <li>ipinfo</li> <li>ipquery</li> <li>webscout</li> </ul> <p>Dependency Requirement</p> <p>You must enable at least one of these engines (ipapi, ipinfo, ipquery, or webscout) for the Bad ASN Check to function. The engine will skip analysis if no ASN data is available.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#2-background-service","title":"2. Background Service","text":"<p>The Bad ASN engine uses a background service that automatically maintains an up-to-date database of malicious ASNs.</p> <p>Background Updater Characteristics:</p> <ul> <li>Update Frequency: Every 24 hours</li> <li>Initial Update: Runs immediately when the application starts</li> <li>Thread Type: Daemon thread (automatically terminates when the application exits)</li> <li>Cache Location: <code>data/bad_asn_cache.json</code></li> <li>Cache Duration: 24 hours</li> </ul> <p>How it works with Gunicorn:</p> <p>When running with Gunicorn, the background service is initialized at the module level, ensuring it runs even with multiple workers. The cache freshness check prevents duplicate downloads across workers.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#data-sources","title":"Data Sources","text":"<p>The engine aggregates data from three authoritative sources:</p>"},{"location":"engines/Bad-ASN-Check-Engine/#1-spamhaus-asndrop","title":"1. Spamhaus ASNDROP","text":"<ul> <li>Source: Spamhaus.org ASNDROP</li> <li>Format: JSONL (JSON Lines)</li> <li>Focus: ASNs controlled by or associated with spam operations</li> <li>Authority: Highly authoritative source for spam-related ASNs</li> <li>Data Included: ASN number, organization name, domain, country code</li> </ul> <p>Example Entry: <pre><code>{\n  \"asn\": \"AS12345\",\n  \"asname\": \"EXAMPLE-AS\",\n  \"domain\": \"example.com\",\n  \"cc\": \"RU\"\n}\n</code></pre></p>"},{"location":"engines/Bad-ASN-Check-Engine/#2-brianhama-bad-asn-list","title":"2. Brianhama Bad ASN List","text":"<ul> <li>Source: Brianhama Bad ASN List (GitHub)</li> <li>Format: CSV</li> <li>Focus: Broad collection of malicious ASNs</li> <li>Data Included: ASN number, entity name</li> </ul> <p>Example Entry: <pre><code>\"ASN\",\"Entity\"\n\"12345\",\"Example Malicious Entity\"\n</code></pre></p>"},{"location":"engines/Bad-ASN-Check-Engine/#3-lethal-forensics-asn-blacklist","title":"3. LETHAL-FORENSICS ASN Blacklist","text":"<ul> <li>Source: LETHAL-FORENSICS Microsoft Analyzer Suite</li> <li>Format: CSV</li> <li>Focus: VPN services and anonymization networks</li> <li>Data Included: ASN number, organization name, VPN services info, date</li> </ul> <p>Example Entry: <pre><code>\"ASN\",\"OrgName\",\"Info\",\"Date\"\n\"174\",\"Cogent Communications\",\"CyberGhost VPN, Mullvad VPN, PIA VPN, ProtonVPN, Pure VPN\",\"2024-12-17\"\n</code></pre></p>"},{"location":"engines/Bad-ASN-Check-Engine/#data-merging-strategy","title":"Data Merging Strategy","text":"<p>When an ASN appears in multiple lists, the information is combined:</p> <pre><code>Spamhaus ASNDROP (Example AS, example.com, RU) + Brianhama Bad ASN List (Example Entity) + LETHAL-FORENSICS ASN Blacklist (Example Org, VPN Services, 2024-12-17)\n</code></pre> <p>This provides comprehensive context for security analysts.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#risk-scoring-algorithm","title":"Risk Scoring Algorithm","text":"<p>The engine calculates a risk score from 0 (low risk) to 100 (critical risk) based on multiple factors:</p> <p>Algorithm Design</p> <p>The risk scoring algorithm was designed with assistance from Claude (Anthropic) to provide balanced and transparent risk assessment. The scoring factors and weights were calibrated to minimize false positives while maintaining high detection accuracy.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#base-score","title":"Base Score","text":"<ul> <li>50 points: Base score for being listed in any bad ASN database</li> </ul>"},{"location":"engines/Bad-ASN-Check-Engine/#factor-1-presence-in-multiple-sources","title":"Factor 1: Presence in Multiple Sources","text":"<ul> <li>+30 points: Listed in all three sources (very high confidence)</li> <li>+20 points: Listed in two sources (higher confidence)</li> <li>+10 points: Listed in Spamhaus only (authoritative source)</li> <li>+8 points: Listed in LETHAL-FORENSICS only (VPN/anonymization focus)</li> </ul>"},{"location":"engines/Bad-ASN-Check-Engine/#factor-2-legitimate-provider-detection","title":"Factor 2: Legitimate Provider Detection","text":"<ul> <li>-30 points: Identified as a legitimate cloud/hosting provider that can be abused</li> </ul> <p>The engine checks for these known legitimate provider keywords in the ASN description: - amazon, aws, google, microsoft, azure - digitalocean, ovh, hetzner, linode, vultr - cloudflare, oracle, ibm, alibaba, tencent - rackspace, contabo, scaleway</p>"},{"location":"engines/Bad-ASN-Check-Engine/#factor-3-high-risk-country-location","title":"Factor 3: High-Risk Country Location","text":"<ul> <li>+10 points: ASN registered in a high-risk country</li> </ul> <p>High-risk countries include: - RU (Russia), CN (China), UA (Ukraine), IR (Iran), KP (North Korea) - MD (Moldova), SC (Seychelles), BY (Belarus) - PK (Pakistan), BD (Bangladesh), VN (Vietnam) - BG (Bulgaria), RO (Romania), IN (India) - HK (Hong Kong), TR (Turkey), ID (Indonesia) - LT (Lithuania), AL (Albania), EE (Estonia)</p>"},{"location":"engines/Bad-ASN-Check-Engine/#score-bounds","title":"Score Bounds","text":"<p>The final score is clamped to ensure it stays within 0-100 range.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#example-calculations","title":"Example Calculations","text":"<p>Example 1: Malicious ASN <pre><code>Base: 50\n+ Listed in Spamhaus and Brianhama: +20\n+ Located in Russia: +10\n= Total: 80/100 (High Risk)\nStatus: malicious\n</code></pre></p> <p>Example 2: Legitimate Provider Abused <pre><code>Base: 50\n+ Listed in LETHAL-FORENSICS only: +8\n- Legitimate provider (AWS): -30\n= Total: 28/100 (Low-Medium Risk)\nStatus: potentially_legitimate\n</code></pre></p> <p>Example 3: Critical Risk <pre><code>Base: 50\n+ Listed in all three sources: +30\n+ Located in China: +10\n= Total: 90/100 (Critical Risk)\nStatus: malicious\n</code></pre></p>"},{"location":"engines/Bad-ASN-Check-Engine/#status-types","title":"Status Types","text":"<p>The engine returns three possible status values:</p>"},{"location":"engines/Bad-ASN-Check-Engine/#1-malicious","title":"1. <code>malicious</code>","text":"<p>The ASN is listed in bad ASN databases and represents a genuine threat.</p> <p>Indicators: - Listed in one or more databases - NOT identified as a legitimate provider - Higher risk scores</p> <p>Example Output: <pre><code>{\n  \"status\": \"malicious\",\n  \"asn\": \"12345\",\n  \"risk_score\": 80,\n  \"source\": \"Spamhaus ASNDROP (...) + Brianhama Bad ASN List (...)\",\n  \"details\": \"ASN 12345 is listed in bad ASN databases. Risk Score: 80/100. Source: ...\",\n  \"asn_org_name\": \"Example Malicious Org\"\n}\n</code></pre></p>"},{"location":"engines/Bad-ASN-Check-Engine/#2-potentially_legitimate","title":"2. <code>potentially_legitimate</code>","text":"<p>The ASN is listed BUT belongs to a legitimate cloud/hosting provider that can be abused.</p> <p>Indicators: - Listed in one or more databases - Identified as a legitimate provider (AWS, Google, Azure, etc.) - Lower risk scores due to -30 penalty</p> <p>Example Output: <pre><code>{\n  \"status\": \"potentially_legitimate\",\n  \"asn\": \"16509\",\n  \"risk_score\": 28,\n  \"source\": \"LETHAL-FORENSICS ASN Blacklist (Amazon.com Inc., ProtonVPN, 2024-12-17)\",\n  \"details\": \"ASN 16509 is listed in bad ASN databases BUT this appears to be a legitimate cloud/hosting provider...\",\n  \"legitimate_but_abused\": true,\n  \"asn_org_name\": \"Amazon.com, Inc.\"\n}\n</code></pre></p> <p>Legitimate Provider Context</p> <p>When status is <code>potentially_legitimate</code>, exercise caution but verify further context. The IP may be legitimate traffic from a cloud provider or may be a malicious actor abusing legitimate infrastructure.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#3-unlisted","title":"3. <code>unlisted</code>","text":"<p>The ASN is NOT listed in any bad ASN database.</p> <p>Example Output: <pre><code>{\n  \"status\": \"unlisted\",\n  \"asn\": \"15169\",\n  \"details\": \"ASN 15169 is not listed in bad ASN databases\"\n}\n</code></pre></p> <p>Unlisted \u2260 Safe</p> <p>An <code>unlisted</code> status only means the ASN is not present in the currently monitored bad ASN databases. This does not guarantee the IP is safe or legitimate. The ASN may be:</p> <ul> <li>A newly created malicious ASN not yet catalogued</li> <li>An ASN used for targeted attacks (not mass campaigns)</li> <li>A compromised legitimate infrastructure not yet blacklisted</li> <li>Updated after the cache's last 24-hour refresh</li> </ul> <p>Always correlate with other engine results (VirusTotal, AbuseIPDB, etc.) for comprehensive analysis.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#usage","title":"Usage","text":""},{"location":"engines/Bad-ASN-Check-Engine/#via-web-interface","title":"Via Web Interface","text":"<ol> <li>Enter an IP address in the search field</li> <li>Enable at least one ASN provider engine (ipapi, ipinfo, ipquery, or webscout)</li> <li>Enable \"Bad ASN Check\"</li> <li>Submit the analysis</li> </ol>"},{"location":"engines/Bad-ASN-Check-Engine/#via-api","title":"Via API","text":"<pre><code>curl -X POST \"http://localhost:5000/api/analyze\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"text\": \"1.2.3.4\",\n    \"engines\": [\"ipapi\", \"bad_asn\"]\n  }'\n</code></pre> <p>Engine Order</p> <p>The Bad ASN Check engine runs in Phase 3 (Post-Pivot) to ensure ASN data from geolocation engines is available. You don't need to worry about execution order - the system handles this automatically.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#gui-display","title":"GUI Display","text":""},{"location":"engines/Bad-ASN-Check-Engine/#card-view","title":"Card View","text":"<p>The card view displays: - Status Badge: Color-coded (Red for malicious, Orange for potentially legitimate, Green for unlisted) - Risk Score: Displayed with matching color - ASN Number: The numeric ASN identifier - Organization: The ASN organization name (from context engines) - Source: Combined source information with all details - Details: Human-readable explanation</p> <p>Status Colors: - \ud83d\udd34 Red (malicious): ASN is listed and represents a genuine threat - \ud83d\udfe0 Orange (potentially_legitimate): Legitimate provider potentially abused - \ud83d\udfe2 Green (unlisted): ASN is not listed  </p>"},{"location":"engines/Bad-ASN-Check-Engine/#table-view","title":"Table View","text":"<p>Compact version showing: - Status badge with risk score - ASN number - Organization (if available) - Abbreviated source information</p>"},{"location":"engines/Bad-ASN-Check-Engine/#export","title":"Export","text":"<p>When exporting results to CSV/Excel, the following fields are included:</p> <ul> <li><code>bad_asn_status</code>: Status value (malicious, potentially_legitimate, unlisted, N/A)</li> <li><code>bad_asn_asn</code>: ASN number</li> <li><code>bad_asn_source</code>: Combined source information</li> <li><code>bad_asn_details</code>: Full details text</li> <li><code>bad_asn_legitimate_but_abused</code>: Boolean flag</li> <li><code>bad_asn_risk_score</code>: Numeric risk score (0-100)</li> <li><code>bad_asn_org_name</code>: Organization name from context</li> </ul>"},{"location":"engines/Bad-ASN-Check-Engine/#troubleshooting","title":"Troubleshooting","text":""},{"location":"engines/Bad-ASN-Check-Engine/#no-asn-data-available","title":"No ASN Data Available","text":"<p>Problem: The engine returns \"No ASN data available\"</p> <p>Solution: Enable at least one ASN provider engine: - ipapi (recommended) - ipinfo - ipquery - webscout</p>"},{"location":"engines/Bad-ASN-Check-Engine/#cache-not-updating","title":"Cache Not Updating","text":"<p>Problem: The cache file isn't being updated</p> <p>Solutions: 1. Check file permissions: Ensure the <code>data/</code> directory is writable 2. Check network connectivity: Verify the application can reach external sources 3. Check proxy settings: If using a proxy, ensure it's correctly configured 4. Manual cache update: Delete <code>data/bad_asn_cache.json</code> to force a fresh download 5. Check logs: Look for error messages in the application logs</p>"},{"location":"engines/Bad-ASN-Check-Engine/#proxy-blocking-github","title":"Proxy Blocking GitHub","text":"<p>Problem: Your proxy blocks GitHub raw content URLs</p> <p>Solution:  - Whitelist the following domains in your proxy:   - <code>www.spamhaus.org</code>   - <code>raw.githubusercontent.com</code> - Or temporarily disable proxy for these requests (not recommended)</p>"},{"location":"engines/Bad-ASN-Check-Engine/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Memory Usage: The cache file typically contains 1000-2000 ASNs, using minimal memory (~500KB-1MB)</li> <li>Disk Usage: Cache file is typically &lt; 2MB</li> <li>Network Usage: Downloads occur once every 24 hours, total ~100KB</li> <li>Analysis Speed: ASN lookup is instantaneous (in-memory dictionary lookup)</li> <li>No Rate Limits: Since it's a local cache, there are no API rate limits</li> </ul>"},{"location":"engines/Bad-ASN-Check-Engine/#best-practices","title":"Best Practices","text":"<ol> <li>Always enable ipapi: It provides the most reliable ASN data</li> <li>Review potentially_legitimate results: Don't automatically dismiss them as safe</li> <li>Consider context: Look at other engine results (VirusTotal, AbuseIPDB) for comprehensive analysis</li> <li>Monitor cache updates: Check logs to ensure the background updater is working</li> <li>Use in combination: Combine with other risk engines for best results</li> </ol>"},{"location":"engines/Bad-ASN-Check-Engine/#security-considerations","title":"Security Considerations","text":""},{"location":"engines/Bad-ASN-Check-Engine/#false-positives","title":"False Positives","text":"<p>Legitimate Providers: The engine specifically handles legitimate cloud providers (AWS, Google, Azure, etc.) by flagging them as <code>potentially_legitimate</code> rather than <code>malicious</code>. Always verify the context.</p> <p>VPN Services: Many VPN services use ASNs from the LETHAL-FORENSICS list. VPN usage alone isn't malicious - consider the broader context.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#false-negatives","title":"False Negatives","text":"<p>New Malicious ASNs: The cache updates every 24 hours. Brand new malicious ASNs may not be detected immediately.</p> <p>Unlisted ASNs: An <code>unlisted</code> status doesn't guarantee the IP is safe - it just means the ASN isn't in known bad ASN databases.</p>"},{"location":"engines/Bad-ASN-Check-Engine/#technical-implementation","title":"Technical Implementation","text":""},{"location":"engines/Bad-ASN-Check-Engine/#engine-class","title":"Engine Class","text":"<pre><code>class BadASNEngine(BaseEngine):\n    @property\n    def name(self) -&gt; str:\n        return \"bad_asn\"\n\n    @property\n    def supported_types(self) -&gt; list[str]:\n        return [\"IPv4\", \"IPv6\"]\n\n    @property\n    def execute_after_reverse_dns(self) -&gt; bool:\n        return True  # Phase 3: Post-Pivot\n</code></pre>"},{"location":"engines/Bad-ASN-Check-Engine/#background-service","title":"Background Service","text":"<pre><code>def background_updater():\n    \"\"\"Updates the bad ASN cache every 24 hours.\"\"\"\n    logger.info(\"Bad ASN background updater started\")\n    update_bad_asn_cache()  # Initial update\n\n    while True:\n        time.sleep(CACHE_MAX_AGE)  # 24 hours\n        update_bad_asn_cache()\n</code></pre>"},{"location":"engines/Bad-ASN-Check-Engine/#cache-structure","title":"Cache Structure","text":"<pre><code>{\n  \"last_updated\": 1706281234.567,\n  \"asns\": {\n    \"12345\": \"Spamhaus ASNDROP (Example AS, example.com, RU)\",\n    \"67890\": \"Brianhama Bad ASN List (Example Entity)\",\n    \"174\": \"LETHAL-FORENSICS ASN Blacklist (Cogent Communications, Multiple VPNs, 2024-12-17)\"\n  }\n}\n</code></pre>"},{"location":"engines/Bad-ASN-Check-Engine/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements being considered:</p> <ul> <li>Additional data sources</li> <li>Custom ASN blacklist/whitelist support</li> </ul>"},{"location":"engines/Bad-ASN-Check-Engine/#support","title":"Support","text":"<p>For issues, questions, or contributions related to the Bad ASN Check engine:</p> <ul> <li>GitHub Issues: Report a bug or request a feature</li> <li>Discussions: Ask questions or share ideas</li> <li>Documentation: Main documentation</li> </ul>"},{"location":"engines/Bad-ASN-Check-Engine/#license","title":"License","text":"<p>The Bad ASN Check engine is part of Cyberbro and is licensed under the same terms. The data sources have their own licenses:</p> <ul> <li>Spamhaus ASNDROP: Spamhaus License</li> <li>Brianhama Bad ASN List: GitHub Repository</li> <li>LETHAL-FORENSICS ASN Blacklist: Microsoft Analyzer Suite</li> </ul>"},{"location":"integrations/Cyberbro-CLI/","title":"Cyberbro CLI","text":"<p>Cyberbro CLI is a command-line interface tool that allows you to interact with your Cyberbro instance directly from your terminal.</p>"},{"location":"integrations/Cyberbro-CLI/#overview","title":"Overview","text":"<p>The CLI tool provides a convenient way to submit observables and retrieve analysis results without using the web interface. This is particularly useful for automation, scripting, and integrating Cyberbro into your security workflows.</p>"},{"location":"integrations/Cyberbro-CLI/#features","title":"Features","text":"<ul> <li>Submit single or multiple observables for analysis</li> <li>Retrieve analysis results in various formats (JSON, CSV, etc.)</li> <li>Read IOC from files and submit them in bulk</li> <li>Use proxy settings for network communication with </li> </ul>"},{"location":"integrations/Cyberbro-CLI/#installation-documentation","title":"Installation &amp; Documentation","text":"<p>For detailed installation instructions, usage examples, and documentation, please visit the official repository:</p> <p>Cyberbro CLI on GitHub</p>"},{"location":"integrations/Cyberbro-CLI/#getting-started","title":"Getting Started","text":"<p>Visit the GitHub repository</p>"},{"location":"integrations/Cyberbro-browser-extension/","title":"Installing Cyberbro Extension","text":"<p>Tip</p> <p>This extension requires a running instance of Cyberbro. If you do not have Cyberbro installed, check this doc for instructions on how to set it up.</p>"},{"location":"integrations/Cyberbro-browser-extension/#get-the-extension-with-the-stores","title":"Get the extension with the stores","text":"<p>Info</p> <p>If you are using a reverse proxy with Cyberbro, ensure that the CORS headers are properly set and that the certificated is trusted on you computer or verified. Without the correct CORS configuration and certificates trust chain (pretty basic, but you can do hardening), the extension will not function correctly. See the example with Caddy.</p> <p>For localhost:5000 version of Cyberbro (e.g. on your machine with Docker), CORS is already enabled by default in Flask, so no additional configuration is needed.</p>"},{"location":"integrations/Cyberbro-browser-extension/#demo","title":"Demo","text":""},{"location":"integrations/Cyberbro-browser-extension/#development","title":"Development","text":""},{"location":"integrations/Cyberbro-browser-extension/#prerequisites","title":"Prerequisites","text":"<ul> <li>Google Chrome / Microsoft Edge / Firefox browser</li> <li>Git</li> </ul>"},{"location":"integrations/Cyberbro-browser-extension/#steps-to-install-on-chrome-and-edge-for-development","title":"Steps to Install on Chrome and Edge for development","text":"<ol> <li> <p>Clone the Repository <pre><code>git clone https://github.com/stanfrbd/cyberbro-chrome-extension.git\ncd cyberbro-chrome-extension\n</code></pre></p> </li> <li> <p>Load the Extension in Chrome</p> <ul> <li>Open Chrome and navigate to <code>chrome://extensions/</code>.</li> <li>Enable \"Developer mode\" by toggling the switch in the top right corner.</li> <li>Click on \"Load unpacked\" and select the <code>cyberbro-chrome-extension</code> directory.</li> </ul> </li> <li> <p>Load the Extension in Edge</p> <ul> <li>Open Edge and navigate to <code>edge://extensions/</code>.</li> <li>Enable \"Developer mode\" by toggling the switch in the bottom left corner.</li> <li>Click on \"Load unpacked\" and select the <code>cyberbro-chrome-extension</code> directory.</li> </ul> </li> </ol>"},{"location":"integrations/Cyberbro-browser-extension/#steps-to-install-on-firefox-for-development","title":"Steps to Install on Firefox for development","text":"<p>Dev mode:</p> <ol> <li>Clone the repository:     <pre><code>git clone https://github.com/stanfrbd/cyberbro-firefox-extension.git\n</code></pre></li> <li>Navigate to the extension directory:     <pre><code>cd cyberbro-firefox-extension\n</code></pre></li> <li>Open Firefox and go to <code>about:debugging</code>:<ul> <li>Click on \"This Firefox\" in the sidebar.</li> <li>Click on \"Load Temporary Add-on...\"</li> <li>Select the <code>manifest.json</code> file from the cloned repository.</li> </ul> </li> </ol> <p>The extension should now be installed in development mode and ready for testing.</p>"},{"location":"integrations/Cyberbro-browser-extension/#extension-options","title":"Extension options","text":"<p>After installing the extension, you can configure it by clicking on the extension icon in the browser toolbar and selecting \"Options\".</p> <p>The extension options include: - Cyberbro URL: The URL of your Cyberbro instance (e.g. <code>http://127.0.0.1:5000</code> - default). This URL is used to send requests to Cyberbro API. - api-prefix (optional): The prefix for the Cyberbro API (e.g. <code>/api</code> - default). This prefix is used to send requests to Cyberbro API. - Selected engines: The list of engines that will be used to search for the selected text. You can enable or disable engines by checking or unchecking the checkboxes.</p> <p>Note</p> <p>The extension will not work if the Cyberbro instance is not running or the URL is incorrect. The engines will not work if the Cyberbro instance does not have the secrets file properly configured.</p> <p></p>"},{"location":"integrations/Cyberbro-browser-extension/#usage","title":"Usage","text":"<p>To use the extension, select some text on a webpage, right-click, and choose \"Analyze with Cyberbro\". The extension will send the selected text to Cyberbro, which will search for it using the enabled engines.</p> <p>See the dedicated repo for Chrome and Edge See the dedicated repo for Firefox</p>"},{"location":"integrations/Cyberbro-browser-extension/#privacy","title":"Privacy","text":"<p>No information is sent somewhere else than your Cyberbro instance (the one you set in \"Cyberbro URL\" section).</p>"},{"location":"integrations/Cyberbro-in-KASM-Workspaces/","title":"Cyberbro has now a KASM Workspaces version","text":"<p>Info</p> <p>Kasm Workspaces is a docker container streaming platform for delivering browser-based access to desktops, applications, and web services. Link of Cyberbro KASM version (official image from KASM): https://hub.docker.com/r/kasmweb/cyberbro</p>"},{"location":"integrations/Cyberbro-in-KASM-Workspaces/#demo","title":"Demo","text":""},{"location":"integrations/Cyberbro-in-KASM-Workspaces/#installation","title":"Installation","text":""},{"location":"integrations/Cyberbro-in-KASM-Workspaces/#images-for-cyberbro-on-dockerhub-are-built-regularly-by-kasm-team-and-we-thank-them-for-that","title":"Images for Cyberbro on DockerHub are built regularly by KASM team (and we thank them for that!)","text":"<ul> <li>Link: https://hub.docker.com/r/kasmweb/cyberbro</li> <li>See more on: https://hub.docker.com/u/kasmweb for the other images provided by KASM team.</li> </ul>"},{"location":"integrations/Cyberbro-in-KASM-Workspaces/#example-of-config-in-the-kasm-gui","title":"Example of config in the KASM GUI","text":"<p>You can use the tags: </p> <p></p> <ul> <li><code>1.18.0</code> and later matching your version.</li> </ul> <p></p>"},{"location":"integrations/Cyberbro-in-KASM-Workspaces/#environment-variables","title":"Environment Variables","text":""},{"location":"integrations/Cyberbro-in-KASM-Workspaces/#firefox-configuration","title":"Firefox Configuration","text":"<ul> <li><code>FIREFOX_APP_ARGS</code> - Additional arguments to pass to firefox when launched.</li> </ul>"},{"location":"integrations/Cyberbro-in-KASM-Workspaces/#cyberbro-configuration-with-optional-environment-variables","title":"Cyberbro Configuration with optional environment variables","text":"<p>All the environment variables are available in the Cyberbro documentation.</p> <p>Note: if you set <code>GUI_ENABLED_ENGINES</code> to <code>\"\"</code> then all engines will be enabled in the GUI. By default (even if the variable is not set or enabled), all free engines will be enabled in the GUI.</p> <p>Refer to https://docs.cyberbro.net/ for more information.</p> <p>You must edit the config in your KASM Cyberbro Workspace settings to add these environment variables, according to KASM Workspaces documentation examples</p> <p></p>"},{"location":"integrations/Reverse-Proxy-configuration-%E2%80%90-Caddy/","title":"Reverse Proxy Configuration (Caddy)","text":"<ol> <li>Install <code>caddy</code> using the official documentation</li> <li>Edit the Caddyfile <pre><code>sudo nano /etc/caddy/Caddyfile\n</code></pre></li> <li>Add the following <pre><code># where example.com is your base domain\n# 127.0.0.1 is your host. It can be the IP of the docker container.\ncyberbro.example.com {\n        reverse_proxy http://127.0.0.1:5000\n        header {\n            Access-Control-Allow-Origin https://cyberbro.example.com # be very careful, you can put * at your own risk.\n        }\n}\n</code></pre></li> <li> <p>Reload the configuration <pre><code>sudo systemctl reload caddy\n</code></pre> or  <pre><code>sudo service caddy reload\n</code></pre></p> </li> <li> <p>Access https://cyberbro.example.com (with an automatic Let's Encrypt certificate), that's great with <code>caddy</code></p> </li> </ol> <p>Warning</p> <p>Make sure to set up proper filtering and security for your reverse proxy, especially if you are exposing Cyberbro to the internet (which is not recommended without proper security measures like WAF, external authentication tool... etc.).</p>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/","title":"Using Cyberbro MCP for LLM Integrations","text":""},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#overview","title":"Overview","text":"<p>Cyberbro MCP is a Model Context Protocol (MCP) server that enables Large Language Models (LLMs) to extract, analyze, and check the reputation of Indicators of Compromise (IoCs) from unstructured input, leveraging multiple threat intelligence sources.</p> <p>Info</p> <p>MCP is a standard that allows applications to provide context and functionality to LLMs in a secure, standardized way\u2014similar to a web API, but designed for LLM integrations.</p> <p></p> <p>Checkout Cyberbro repository for more information about the platform.</p> <p>MCP servers can:</p> <ul> <li>Expose data through Resources (to load information into the LLM's context)</li> <li>Provide functionality through Tools (to execute code or perform actions)</li> <li>Define interaction patterns through Prompts (reusable templates for LLM interactions)</li> </ul> <p>This server implements the Tools functionality of MCP, offering a suite of tools for extracting IoCs from text, analyzing them, and checking their reputation across various threat intelligence sources. It allows AI systems like Claude to retrieve, analyze, and act on threat intelligence in real-time.</p>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#key-features","title":"Key Features","text":"<ul> <li>Multi-Service Reputation Checks: Query IPs, domains, hashes, URLs, and Chrome extension IDs across many threat intelligence sources.</li> <li>Integrated Reporting: Get detailed, exportable reports and analysis history.</li> <li>Platform Integrations: Supports Microsoft Defender for Endpoint, CrowdStrike, OpenCTI, and more.</li> <li>Advanced Search &amp; Visualization: Search with Grep.App, check for breaches, and visualize results.</li> <li>Beginner-friendly and LLM-ready (no manual UI needed)</li> <li>Unique support for Chrome extension IDs and advanced TLD handling</li> </ul>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#installation","title":"Installation","text":""},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#option-1-using-docker-recommended","title":"Option 1: Using Docker (Recommended)","text":"<ol> <li>Export your Cyberbro config as an environment variable:     <pre><code>export CYBERBRO_URL=http://localhost:5000\nexport API_PREFIX=api\n</code></pre></li> <li>Pull the Docker image from GitHub Container Registry:     <pre><code>docker pull ghcr.io/stanfrbd/mcp-cyberbro:latest\n</code></pre></li> </ol>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#option-2-local-installation","title":"Option 2: Local Installation","text":"<ol> <li>Clone this repository:     <pre><code>git clone https://github.com/stanfrbd/mcp-cyberbro.git\ncd mcp-cyberbro\n</code></pre></li> <li>Install the required dependencies:     <pre><code>uv run pip install -r requirements.txt\n</code></pre></li> <li> <p>Set environment variables for MCP configuration or provide them as CLI arguments:</p> <p>Option A: Using environment variables <pre><code>export CYBERBRO_URL=http://localhost:5000\nexport API_PREFIX=api\n</code></pre></p> <p>Option B: Using CLI arguments <pre><code>uv run mcp-cyberbro-server.py --cyberbro_url http://localhost:5000 --api_prefix api\n</code></pre></p> </li> <li> <p>Start the MCP server:     <pre><code>uv run mcp-cyberbro-server.py\n</code></pre>     The server will listen for MCP protocol messages on stdin/stdout and use the environment variables as shown in the Claude Desktop configuration example.</p> </li> </ol>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#optional-environment-variables","title":"Optional environment variables","text":"<ul> <li><code>SSL_VERIFY</code>: Set to <code>false</code> to disable SSL verification for the Cyberbro URL.</li> <li><code>API_PREFIX</code>: Set to a custom prefix for the Cyberbro API.</li> </ul>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#optional-arguments","title":"Optional arguments","text":"<ul> <li><code>--no_ssl_verify</code>: Disable SSL verification for the Cyberbro URL.</li> <li><code>--api_prefix</code>: Set a custom prefix for the Cyberbro API.</li> </ul>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#integration-with-claude-desktop","title":"Integration with Claude Desktop","text":""},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#using-with-claude-desktop-docker-recommended","title":"Using with Claude Desktop (Docker) - Recommended","text":"<p>Warning</p> <p>Make sure Docker is installed and running on your machine (e.g., Docker Desktop).</p> <p>Add to your <code>claude_desktop_config.json</code>:</p> <pre><code>\"mcpServers\": {\n  \"cyberbro\": {\n     \"command\": \"docker\",\n     \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"CYBERBRO_URL\",\n        \"-e\",\n        \"API_PREFIX\",\n        \"ghcr.io/stanfrbd/mcp-cyberbro:latest\"\n     ],\n     \"env\": {\n        \"CYBERBRO_URL\": \"http://localhost:5000\",\n        \"API_PREFIX\": \"api\"\n     }\n  }\n}\n</code></pre>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#using-with-claude-desktop-local","title":"Using with Claude Desktop (Local)","text":"<p>Warning</p> <p>While it can be launched with Python directly, use <code>venv</code> or <code>uv</code> to avoid conflicts with other Python packages.</p> <pre><code>\"mcpServers\": {\n  \"cyberbro\": {\n     \"command\": \"uv\",\n     \"args\": [\n        \"run\",\n        \"C:\\\\Users\\\\path\\\\to\\\\mcp-cyberbro-server.py\"\n     ],\n     \"env\": {\n        \"CYBERBRO_URL\": \"http://localhost:5000\",\n        \"API_PREFIX\": \"api\"\n     }\n  }\n}\n</code></pre> <p>Tip</p> <p>Make sure you have exported your Cyberbro config as environment variables (e.g., <code>CYBERBRO_URL</code> and <code>API_PREFIX</code>) before starting Claude Desktop.</p>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#using-with-other-llms-and-mcp-clients","title":"Using with Other LLMs and MCP Clients","text":"<p>This MCP server can be used with any LLM or MCP client that supports the Model Context Protocol. The server listens for MCP protocol messages on stdin/stdout, making it compatible with various LLMs and clients. It is designed to work best with LLMs that can interpret and execute MCP commands correctly (e.g., Claude Desktop).</p> <p>Documentation for other LLMs and MCP clients with Open Web UI: https://docs.openwebui.com/openapi-servers/mcp/</p> <p>It uses an OpenAPI proxy to expose the MCP server as an OpenAPI server, allowing you to interact with it using standard HTTP requests.</p>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#example-of-usage-with-openapi-proxy","title":"Example of usage with OpenAPI Proxy","text":"<p>Tip</p> <p>Install <code>mcpo</code> via <code>pip install mcpo</code> or via <code>uv</code>.</p> <ol> <li>Create a <code>config.json</code> file in the mcp folder:     <pre><code>{\n  \"mcpServers\": {\n     \"cyberbro\": {\n        \"command\": \"uv\",\n        \"args\": [\n          \"run\",\n          \"./mcp-cyberbro-server.py\"\n        ],\n        \"env\": {\n          \"CYBERBRO_URL\": \"https://cyberbro.lab.local\",\n          \"API_PREFIX\": \"api\"\n        }\n     }\n  }\n}\n</code></pre></li> <li>Run the MCP server:     <pre><code>uvx mcpo --config config.json --port 8000\n</code></pre></li> <li>The server will start and listen for requests on port 8000. Access OpenAPI docs at <code>http://localhost:8000/docs</code>.</li> </ol> <p>You can configure your MCP client to connect to the server at <code>http://localhost:8000/cyberbro</code>. The OpenAPI specification will be available at <code>http://localhost:8000/cyberbro/openapi.json</code>.</p>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#example-with-open-web-ui","title":"Example with Open Web UI","text":"<p>Warning</p> <p>Use Native function calling and a MCP compatible model (e.g. OpenAI: <code>gpt-4o</code>).</p> <p></p> <p>See: https://docs.openwebui.com/openapi-servers/open-webui#optional-step-4-use-native-function-calling-react-style-tool-use-</p>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#available-tools","title":"Available Tools","text":"<p>The MCP server provides the following tools:</p> Tool Name Description Arguments analyze_observable Extracts and analyzes IoCs from input text using selected engines. Returns analysis ID. <code>text</code> (string), <code>engines</code> (list, optional) is_analysis_complete Checks if the analysis for a given ID is finished. Returns status. <code>analysis_id</code> (string) get_analysis_results Retrieves the results of a completed analysis by ID. <code>analysis_id</code> (string) get_engines Lists available analysis engines supported by Cyberbro. (none) get_web_url Returns the web URL for the Cyberbro instance. <code>analysis_id</code> (string)"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#example-queries","title":"Example Queries","text":"<p>Here are some example queries you can run using the MCP server with an LLM like Claude:</p>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#getting-indicator-details","title":"Getting Indicator Details","text":"<pre><code>Cyberbro: Check indicators for target.com\n</code></pre> <pre><code>Can you check this IP reputation with Cyberbro? 192.168.1.1\nUse github, google and virustotal engines.\n</code></pre> <pre><code>I want to analyze the domain example.com. What can Cyberbro tell me about it?\nUse max 3 engines.\n</code></pre> <pre><code>Analyze these observables with Cyberbro: suspicious-domain.com, 8.8.8.8, and 44d88612fea8a8f36de82e1278abb02f.  \nUse all available engines.\n</code></pre>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#observable-analysis","title":"Observable Analysis","text":"<pre><code>I found this (hash|domain|url|ip|extension)  \nCan you submit it for analysis to Cyberbro and analyze the results?\n</code></pre> <p>These example queries show how Cyberbro leverages LLMs to interpret your intent and automatically select the right MCP tools, allowing you to interact with Cyberbro easily\u2014without needing to make the analysis yourself.</p>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#osint-investigation","title":"OSINT investigation","text":"<pre><code>Create an OSINT report for the domain example.com using Cyberbro.\nUse all available engines and pivot on the results for more information.\nUse a maximum of 10 analysis requests.\n</code></pre>"},{"location":"integrations/Use-Cyberbro-MCP-for-LLM/#resources","title":"Resources","text":"<ul> <li>Cyberbro MCP GitHub</li> <li>Cyberbro</li> <li>Model Context Protocol</li> </ul> <p>Licensed under MIT. See the repo for details.</p>"},{"location":"quick-start/API-usage-and-engine-names/","title":"API Usage & Engine Names","text":""},{"location":"quick-start/API-usage-and-engine-names/#cyberbro-api","title":"Cyberbro API","text":"<ul> <li>The API is available at <code>/api/</code> (or your custom prefix if you have changed it using the advanced options) and can be accessed via the GUI or command-line.</li> </ul> <p>There are currently 3 endpoints:</p> <ul> <li><code>/api/analyze</code> - Analyze a text and return analysis ID (JSON).</li> <li><code>/api/is_analysis_complete/&lt;analysis_id&gt;</code> - Check if the analysis is complete (JSON).</li> <li><code>/api/results/&lt;analysis_id&gt;</code> - Retrieve the results of a previous analysis (JSON).</li> </ul>"},{"location":"quick-start/API-usage-and-engine-names/#1-analyze-endpoint","title":"1. Analyze Endpoint","text":"<p>Submit an observable (e.g., domain, IP, URL, hash) for analysis using one or more engines.</p> cURLPythonJavaScriptHTTP Request<pre><code>curl -X POST \"http://localhost:5000/api/analyze\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n  \"text\": \"cyberbro.net\",\n  \"engines\": [\"reverse_dns\", \"rdap_whois\"]\n  }'\n</code></pre> Request<pre><code>import requests\nimport json\n\nurl = \"http://localhost:5000/api/analyze\"\nheaders = {\"Content-Type\": \"application/json\"}\ndata = {\n  \"text\": \"cyberbro.net\",\n  \"engines\": [\"reverse_dns\", \"rdap_whois\"]\n}\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\nprint(response.json())\n</code></pre> Request<pre><code>fetch(\"http://localhost:5000/api/analyze\", {\n  method: \"POST\",\n  headers: {\n    \"Content-Type\": \"application/json\"\n  },\n  body: JSON.stringify({\n    text: \"cyberbro.net\",\n    engines: [\"reverse_dns\", \"rdap_whois\"]\n  })\n})\n.then(response =&gt; response.json())\n.then(data =&gt; console.log(data));\n</code></pre> Request<pre><code>POST /api/analyze HTTP/1.1\nHost: localhost:5000\nContent-Type: application/json\n\n{\n  \"text\": \"cyberbro.net\",\n  \"engines\": [\"reverse_dns\", \"rdap_whois\"]\n}\n</code></pre> Example Response<pre><code>{\n  \"analysis_id\": \"e88de647-b153-4904-91e5-8f5c79174854\",\n  \"link\": \"/results/e88de647-b153-4904-91e5-8f5c79174854\"\n}\n</code></pre>"},{"location":"quick-start/API-usage-and-engine-names/#2-check-analysis-status-endpoint","title":"2. Check Analysis Status Endpoint","text":"<p>Check if the analysis is complete by querying the status endpoint with the returned <code>analysis_id</code>.</p> cURLPythonJavaScriptHTTP Request<pre><code>curl \"http://localhost:5000/api/is_analysis_complete/e88de647-b153-4904-91e5-8f5c79174854\"\n</code></pre> Request<pre><code>import requests\n\nurl = \"http://localhost:5000/api/is_analysis_complete/e88de647-b153-4904-91e5-8f5c79174854\"\nresponse = requests.get(url)\nprint(response.json())\n</code></pre> Request<pre><code>fetch(\"http://localhost:5000/api/is_analysis_complete/e88de647-b153-4904-91e5-8f5c79174854\")\n.then(response =&gt; response.json())\n.then(data =&gt; console.log(data));\n</code></pre> Request<pre><code>GET /api/is_analysis_complete/e88de647-b153-4904-91e5-8f5c79174854 HTTP/1.1\nHost: localhost:5000\n</code></pre> Example Response<pre><code>{\n  \"complete\": true\n}\n</code></pre>"},{"location":"quick-start/API-usage-and-engine-names/#3-retrieve-analysis-results-endpoint","title":"3. Retrieve Analysis Results Endpoint","text":"<p>Once the analysis is complete, retrieve the results using the <code>analysis_id</code>.</p> cURLPythonJavaScriptHTTP Request<pre><code>curl \"http://localhost:5000/api/results/e88de647-b153-4904-91e5-8f5c79174854\"\n</code></pre> Request<pre><code>import requests\n\nurl = \"http://localhost:5000/api/results/e88de647-b153-4904-91e5-8f5c79174854\"\nresponse = requests.get(url)\nprint(response.json())\n</code></pre> Request<pre><code>fetch(\"http://localhost:5000/api/results/e88de647-b153-4904-91e5-8f5c79174854\")\n.then(response =&gt; response.json())\n.then(data =&gt; console.log(data));\n</code></pre> Request<pre><code>GET /api/results/e88de647-b153-4904-91e5-8f5c79174854 HTTP/1.1\nHost: localhost:5000\n</code></pre> Example Response<pre><code>[\n  {\n  \"observable\": \"cyberbro.net\",\n  \"rdap_whois\": {\n    \"abuse_contact\": \"registrar-abuse@cloudflare.com\",\n    \"creation_date\": \"2024-12-20\",\n    \"data_source\": \"rdap\",\n    \"emails\": [\n      \"registrar-abuse@cloudflare.com\"\n    ],\n    \"expiration_date\": \"2026-12-20\",\n    \"link\": \"https://rdap.verisign.com/net/v1/domain/CYBERBRO.NET\",\n    \"name_servers\": [\n      \"anderson.ns.cloudflare.com\",\n      \"lisa.ns.cloudflare.com\"\n    ],\n    \"organization\": null,\n    \"registrant\": null,\n    \"registrant_country\": null,\n    \"registrant_email\": null,\n    \"registrar\": \"Cloudflare, Inc.\",\n    \"update_date\": \"2025-11-20\"\n  },\n  \"reverse_dns\": {\n    \"reverse_dns\": [\n      \"172.67.197.226\",\n      \"104.21.42.7\"\n    ]\n  },\n  \"reversed_success\": true,\n  \"type\": \"FQDN\"\n  }\n]\n</code></pre> <p>Tip</p> <p>Always check the analysis status before retrieving results to ensure the analysis is complete. For more advanced usage, such as bypassing cache or customizing engine selection, refer to the sections below.</p>"},{"location":"quick-start/API-usage-and-engine-names/#note-about-caching-and-ignoring-cache","title":"Note about caching and ignoring cache","text":"<ul> <li> <p>The API results are cached for 24 hours by default. You can change this by modifying the <code>api_cache_timeout</code> parameter in the <code>secrets.json</code> file or by setting the corresponding environment variable. Refer to this document for more details: advanced options.</p> </li> <li> <p>You can bypass caching for a specific request by including <code>\"ignore_cache\": true</code> in the data section of your request. Ignoring the cache will force the system to perform the analysis again. For example:</p> </li> </ul> cURLPythonJavaScriptHTTP Request with Cache Ignored<pre><code>curl -X POST \"http://localhost:5000/api/analyze\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"text\": \"cyberbro.net\",\n    \"engines\": [\"reverse_dns\", \"rdap_whois\"],\n    \"ignore_cache\": true\n  }'\n</code></pre> Request with Cache Ignored<pre><code>import requests\nimport json\nurl = \"http://localhost:5000/api/analyze\"\nheaders = {\"Content-Type\": \"application/json\"}\ndata = {\n    \"text\": \"cyberbro.net\",\n    \"engines\": [\"reverse_dns\", \"rdap_whois\"],\n    \"ignore_cache\": True\n}\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\nprint(response.json())\n</code></pre> Request with Cache Ignored<pre><code>fetch(\"http://localhost:5000/api/analyze\", {\n    method: \"POST\",\n    headers: {\n        \"Content-Type\": \"application/json\"\n    },\n    body: JSON.stringify({\n        text: \"cyberbro.net\",\n        engines: [\"reverse_dns\", \"rdap_whois\"],\n        ignore_cache: true\n    })\n})\n.then(response =&gt; response.json())\n.then(data =&gt; console.log(data));\n</code></pre> Request with Cache Ignored<pre><code>POST /api/analyze HTTP/1.1\nHost: localhost:5000\nContent-Type: application/json\n\n{\n    \"text\": \"cyberbro.net\",\n    \"engines\": [\"reverse_dns\", \"rdap_whois\"],\n    \"ignore_cache\": true\n}\n</code></pre>"},{"location":"quick-start/API-usage-and-engine-names/#list-of-usable-engines-and-their-description-just-like-in-the-html-page","title":"List of usable engines and their description (just like in the HTML page)","text":"<p>Tip</p> <p>Use the property <code>name</code> for the API.</p>"},{"location":"quick-start/API-usage-and-engine-names/#abusix","title":"Abusix","text":"<p>Name: <code>abusix</code> Supports: abuse, free_no_key Explaination: Checks abuse contact with Abusix for IP, reversed obtained IP for a given domain/URL, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#alienvault","title":"Alienvault","text":"<p>Name: <code>alienvault</code> Supports: IP, free API key required Explaination: Checks Alienvault for IP, domain, URL, hash, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#abuseipdb","title":"AbuseIPDB","text":"<p>Name: <code>abuseipdb</code> Supports: IP, free API key required Explaination: Checks AbuseIPDB for IP, reversed obtained IP for a given domain/URL, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#bad-asn-check","title":"Bad ASN Check","text":"<p>Name: <code>bad_asn</code> Supports: IP, risk, free_no_key Explaination: Malicious ASN detection (free, no API key). Checks if IP's ASN is listed in Spamhaus ASNDROP, Brianhama Bad ASN databases, or LETHAL-FORENSICS ASN Blacklist (VPN/anonymization services). Requires ipapi, ipinfo, or ipquery engine for ASN data</p>"},{"location":"quick-start/API-usage-and-engine-names/#crowdstrike","title":"CrowdStrike","text":"<p>Name: <code>crowdstrike</code> Supports: hash, IP, domain, URL Explaination: Checks CrowdStrike for IP, domain, URL, hash, paid API key required with Flacon XDR and Falcon Intelligence licence</p>"},{"location":"quick-start/API-usage-and-engine-names/#criminalip","title":"CriminalIP","text":"<p>Name: <code>criminalip</code> Supports: IP, free or paid API key required Explaination: Checks CriminalIP for IP, reversed obtained IP for a given domain / URL, free or paid API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#crtsh","title":"crt.sh","text":"<p>Name: <code>crtsh</code> Supports: domain, URL, free_no_key Explaination: Checks crt.sh for known subdomain names based on TLS certificates for a given domain / URL, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#dfir-iris","title":"DFIR-IRIS","text":"<p>Name: <code>dfir_iris</code> Supports : domain,URL,IP,hash, free API key required Explanation: Searches DFIR-IRIS globally across all cases for indicators, free, API key required.  </p>"},{"location":"quick-start/API-usage-and-engine-names/#github","title":"Github","text":"<p>Name: <code>github</code> Supports: domain, URL, IP, hash, free_no_key, scraping Explaination: Get Github grep.app API search results for all types of observable, free, no API key  </p>"},{"location":"quick-start/API-usage-and-engine-names/#google","title":"Google","text":"<p>Name: <code>google</code> Supports: domain, URL, IP, hash Explaination: Checks Google Custom Search Engine (CSE) API results for all types of observable, free API required</p>"},{"location":"quick-start/API-usage-and-engine-names/#google-dns-common-records","title":"Google DNS (common records)","text":"<p>Name: <code>google_dns</code> Supports: IP, domain, URL Explaination: Checks Google common DNS records (A, AAAA, CNAME, NS, MX, TXT - including SPF and DMARC, PTR) for IP, domain, URL, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#google-safe-browsing","title":"Google Safe Browsing","text":"<p>Name: <code>google_safe_browsing</code> Supports: risk, domain, IP Explaination: Checks Google Safe Browsing, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#hudson-rock","title":"Hudson Rock","text":"<p>Name: <code>hudsonrock</code> Supports: domain, URL, email, free_no_key Explaination: Searches Hudson Rocks results for domains, URL, Email, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#iocone-html","title":"Ioc.One (HTML)","text":"<p>Name: <code>ioc_one_html</code> Supports: domain, URL, IP, hash, scraping Explaination: Scraps (can be long) Ioc.One HTML search results for all types of observable, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#iocone-pdf","title":"Ioc.One (PDF)","text":"<p>Name: <code>ioc_one_pdf</code> Supports: domain, URL, IP, hash, scraping Explaination: Scraps (can be long) Ioc.One PDF search results for all types of observable, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#ipapi","title":"IPapi","text":"<p>Name: <code>ipapi</code> Supports: default, IP, risk, VPN, proxy, free API key required Explaination: Checks IPapi for IP, reversed obtained IP for a given domain/URL, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#ipinfo","title":"IPinfo","text":"<p>Name: <code>ipinfo</code> Supports: IP Explaination: Checks IPinfo for IP, reversed obtained IP for a given domain/URL, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#ipquery","title":"IPquery","text":"<p>Name: <code>ipquery</code> Supports: IP, risk, VPN, proxy, free_no_key Explaination: Checks IPquery for IP, reversed obtained IP for a given domain/URL, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#microsoft-defender-for-endpoint","title":"Microsoft Defender for Endpoint","text":"<p>Name: <code>mde</code> Supports: hash, IP, domain, URL Explaination: Checks Microsoft Defender for Endpoint, paid API info on Azure required</p>"},{"location":"quick-start/API-usage-and-engine-names/#misp","title":"MISP","text":"<p>Name: <code>misp</code> Supports: IP, domain, URL, hash Explaination: Checks MISP for IP, domain, URL, hash, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#opencti","title":"OpenCTI","text":"<p>Name: <code>opencti</code> Supports: domain, URL, IP, hash Explaination: Searches OpenCTI results for all types of observable, API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#phishtank","title":"Phishtank","text":"<p>Name: <code>phishtank</code> Supports: risk, domain, URL, free_no_key Explaination: Checks Phishtank for domains, URL, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#rdap-whois","title":"RDAP / Whois","text":"<p>Name: <code>rdap_whois</code> Supports: default, abuse, domain, free_no_key Explaination: Checks RDAP / Whois record for domain, URL, no API key required (uses RDAP with WHOIS fallback)</p>"},{"location":"quick-start/API-usage-and-engine-names/#reverse-dns","title":"Reverse DNS","text":"<p>Name: <code>reverse_dns</code> Supports: default, domain, IP, abuse, free_no_key Explaination: Performs a reverse DNS lookup for IP, domain, URL (on the Cyberbro machine)</p>"},{"location":"quick-start/API-usage-and-engine-names/#reversing-labs-spectra-analyze","title":"Reversing Labs Spectra Analyze","text":"<p>Name: <code>rl_analyze</code> Supports: domain, URL, IP, hash, paid API key required Explanation: Looks up observables in the Reversing Labs Spectra Analyze service, paid API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#rosti","title":"R\u00f6sti","text":"<p>Name: <code>rosti</code> Supports: IP, domain, URL, email Explaination: Searches R\u00f6sti threat intelligence IOC data for observed values, API key required (see https://rosti.bin.re/api)</p>"},{"location":"quick-start/API-usage-and-engine-names/#shodan","title":"Shodan","text":"<p>Name: <code>shodan</code> Supports: ports, IP Explaination: Checks Shodan, reversed obtained IP for a given domain/URL, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#spurus","title":"Spur.us","text":"<p>Name: <code>spur</code> Supports: VPN, proxy, paid API key required Explaination: Checks Spur.us for IP, reversed obtained IP for a given domain/URL, paid API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#threatfox","title":"ThreatFox","text":"<p>Name: <code>threatfox</code> Supports: IP, domain, URL, free Explaination: Checks ThreatFox by Abuse.ch for IP, domains, URL, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#urlscan","title":"URLscan","text":"<p>Name: <code>urlscan</code> Supports: domain, URL, IP, hash, free_no_key Explaination: Checks URLscan for all types of observable, free, no API key</p>"},{"location":"quick-start/API-usage-and-engine-names/#virustotal","title":"VirusTotal","text":"<p>Name: <code>virustotal</code> Supports: hash, risk, IP, domain, URL Explaination: Checks VirusTotal for IP, domain, URL, hash, free API key required</p>"},{"location":"quick-start/API-usage-and-engine-names/#webscout","title":"WebScout","text":"<p>Name: <code>webscout</code> Supports: IP, free or paid API key required Explaination: Checks WebScout for IP, reversed obtained IP for a given domain / URL, free or paid API key required</p>"},{"location":"quick-start/Advanced-options-for-deployment/","title":"Advanced options for deployment","text":"<p>Tip</p> <p>All variables from <code>secrets.json</code> can be converted to environment variables (uppercase).</p> <p>Note</p> <p>You can add these environment variables in a <code>docker-compose-custom.yml</code> or just a <code>docker-compose-custom.yml</code> with a <code>.env</code>. If you don't specify proxy, no proxy will be used.</p> <p>Here is a list of all available environment variables that can be used with examples:</p> <pre><code>PROXY_URL=http://127.0.0.1:9000\nVIRUSTOTAL=api_key_here\nALIENVAULT=api_key_here\nABUSEIPDB=api_key_here\nIPAPI=api_key_here\nIPINFO=api_key_here\nGOOGLE_CSE_KEY=api_key_here\nGOOGLE_CSE_CX=cx_here\nGOOGLE_SAFE_BROWSING=api_key_here\nMDE_TENANT_ID=api_key_here\nMDE_CLIENT_ID=api_key_here\nMDE_CLIENT_SECRET=api_key_here\nMISP_URL=https://misp.local\nMISP_API_KEY=api_key_here\nSHODAN=api_key_here\nSPUR_US=api_key_here\nTHREATFOX=api_key_here\nOPENCTI_API_KEY=api_key_here\nOPENCTI_URL=https://demo.opencti.io\nCRIMINALIP_API_KEY=api_key_here\nCROWDSTRIKE_CLIENT_ID=client_id_here\nCROWDSTRIKE_CLIENT_SECRET=client_secret_here\nCROWDSTRIKE_FALCON_BASE_URL=https://falcon.crowdstrike.com\nDFIR_IRIS_URL=https://dfir-iris.local\nDFIR_IRIS_API_KEY=token_here\nWEBSCOUT=token_here\nRL_ANALYZE_API_KEY=token_here\nRL_ANALYZE_URL=https://spectra_analyze_url_here\nROSTI_API_KEY=token_here\nSUPERVISORD_WORKERS_COUNT=4\nSUPERVISORD_THREADS_COUNT=4\nSUPERVISORD_TIMEOUT=200\nAPI_PREFIX=my_api\nMAX_FORM_MEMORY_SIZE=1048576\nGUI_ENABLED_ENGINES=reverse_dns,rdap_whois\nCONFIG_PAGE_ENABLED=true\nSSL_VERIFY=true\nGUI_CACHE_TIMEOUT=1800\nAPI_CACHE_TIMEOUT=86400\n</code></pre>"},{"location":"quick-start/Advanced-options-for-deployment/#example-of-custom-docker-compose-file","title":"Example of custom docker compose file","text":"<p>Tip</p> <p>This can be useful when you don't want to build the image yourself. This image is produced by the GitHub actions workflow</p> <pre><code>ghcr.io/stanfrbd/cyberbro:latest\n</code></pre> <p>Example of <code>docker-compose-custom.yml</code> (note: no <code>\"</code> in environment variables)</p> <pre><code>services:\n  web:\n    image: ghcr.io/stanfrbd/cyberbro:latest\n    container_name: cyberbro\n    ports:\n      - \"5000:5000\"\n    environment:\n      - FLASK_ENV=production\n      - ABUSEIPDB=${ABUSEIPDB:-}\n      - ALIENVAULT=${ALIENVAULT:-}\n      - CRIMINALIP_API_KEY=${CRIMINALIP_API_KEY:-}\n      - CROWDSTRIKE_CLIENT_ID=${CROWDSTRIKE_CLIENT_ID:-}\n      - CROWDSTRIKE_CLIENT_SECRET=${CROWDSTRIKE_CLIENT_SECRET:-}\n      - CROWDSTRIKE_FALCON_BASE_URL=${CROWDSTRIKE_FALCON_BASE_URL:-}\n      - DFIR_IRIS_API_KEY=${DFIR_IRIS_API_KEY:-}\n      - DFIR_IRIS_URL=${DFIR_IRIS_URL:-}\n      - GOOGLE_CSE_KEY=${GOOGLE_CSE_KEY:-}\n      - GOOGLE_CSE_CX=${GOOGLE_CSE_CX:-}\n      - GOOGLE_SAFE_BROWSING=${GOOGLE_SAFE_BROWSING:-}\n      - IPAPI=${IPAPI:-}\n      - IPINFO=${IPINFO:-}\n      - MDE_CLIENT_ID=${MDE_CLIENT_ID:-}\n      - MDE_CLIENT_SECRET=${MDE_CLIENT_SECRET:-}\n      - MDE_TENANT_ID=${MDE_TENANT_ID:-}\n      - MISP_API_KEY=${MISP_API_KEY:-}\n      - MISP_URL=${MISP_URL:-}\n      - OPENCTI_API_KEY=${OPENCTI_API_KEY:-}\n      - OPENCTI_URL=${OPENCTI_URL:-}\n      - RL_ANALYZE_API_KEY=${RL_ANALYZE_API_KEY:-}\n      - RL_ANALYZE_URL=${RL_ANALYZE_URL:-}\n      - ROSTI_API_KEY=${ROSTI_API_KEY:-}\n      - SHODAN=${SHODAN:-}\n      - SPUR_US=${SPUR_US:-}\n      - THREATFOX=${THREATFOX:-}\n      - VIRUSTOTAL=${VIRUSTOTAL:-}\n      - WEBSCOUT=${WEBSCOUT:-}\n      - CONFIG_PAGE_ENABLED=${CONFIG_PAGE_ENABLED:-}\n      - SSL_VERIFY=${SSL_VERIFY:-}\n      - PROXY_URL=${PROXY_URL:-}\n      - GUI_CACHE_TIMEOUT=${GUI_CACHE_TIMEOUT1800:-}\n      - API_CACHE_TIMEOUT=${API_CACHE_TIMEOUT86400:-}\n      - GUI_ENABLED_ENGINES=${GUI_ENABLED_ENGINES:-}\n      - SUPERVISORD_WORKERS_COUNT=${SUPERVISORD_WORKERS_COUNT:-}\n      - SUPERVISORD_THREADS_COUNT=${SUPERVISORD_THREADS_COUNT:-}\n      - SUPERVISORD_TIMEOUT=${SUPERVISORD_TIMEOUT:-}\n      - API_PREFIX=${API_PREFIX:-}\n      - MAX_FORM_MEMORY_SIZE=${MAX_FORM_MEMORY_SIZE:-}\n    restart: always\n    volumes:\n      - ./data:/app/data\n      - ./logs:/var/log/cyberbro\n</code></pre> <p>Example of <code>.env</code> file (note: no <code>\"</code> in environment variables)</p> <pre><code>VIRUSTOTAL=api_key_here\nABUSEIPDB=api_key_here\nGUI_ENABLED_ENGINES=reverse_dns,rdap_whois,ipquery,abuseipdb,virustotal,spur,google_safe_browsing,phishtank\nAPI_CACHE_TIMEOUT=1800\n</code></pre> <p>You can use the file <code>.env.sample</code> as a template to create your own <code>.env</code> file.</p> <p>Danger</p> <p>Make sure you use either <code>secrets.json</code> or <code>.env</code> file for your deployment, not both. This may lead to unexpected behavior as the application will try to read both files and may override some values.</p> <p>Note</p> <p><code>./data:/app/data</code>: This maps the <code>data</code> directory on your host machine to the <code>/app/data</code> directory inside the container. This is mandatory for persisting the database <code>results.db</code> that is used by Cyberbro. <code>./logs:/var/log/cyberbro</code>: This maps the <code>logs</code> directory on your host machine to the <code>/var/log/cyberbro</code> directory inside the container. This is useful for persisting log files generated by the application, allowing you to access and analyze logs even after the container is stopped or removed.</p>"},{"location":"quick-start/Advanced-options-for-deployment/#supervisord-options-for-docker-only","title":"Supervisord options (for docker only)","text":"<p>This options will be applied only if the script <code>prod/advanced_config.py</code> is run (automatic in docker)</p> <p>In <code>secrets.json</code>:</p> <ul> <li>Adding <code>\"supervisord_workers_count\": 4</code> in <code>secrets.json</code> will set <code>-w 4</code> in <code>supervisord.conf</code></li> <li>Adding <code>\"supervisord_threads_count\": 4</code> in <code>secrets.json</code> will set <code>-t 4</code> in <code>supervisord.conf</code></li> <li>Adding <code>\"supervisord_timeout\": 200</code> in <code>secrets.json</code> will set <code>--timeout 200</code> in <code>supervisord.conf</code></li> </ul> <p>Or using environment variables:</p> <pre><code>export SUPERVISORD_WORKERS_COUNT=4\nexport SUPERVISORD_THREADS_COUNT=4\nexport SUPERVISORD_TIMEOUT=200\n</code></pre> <p>Note</p> <p>These variables are optional, so if they don't exist in <code>secrets.json</code>, the original config (in <code>prod/supervisord.conf</code>) will be applied by default.</p>"},{"location":"quick-start/Advanced-options-for-deployment/#api-prefix-in-apppy-and-indexhtml-options","title":"API prefix in <code>app.py</code> and <code>index.html</code> options","text":"<p>In <code>secrets.json</code>:</p> <p>Tip</p> <p>By default, the API is accessible at <code>http://cyberbro_instance:5000/api</code></p> <ul> <li>Adding <code>\"api_prefix\": \"my_api\"</code> in <code>secrets.json</code> will set all the original prefix <code>/api/</code> endpoints to be renamed by prefix <code>/my_api/</code> endpoints in the files <code>app.py</code> and <code>index.html</code></li> </ul> <p>Or using environment variables:</p> <pre><code>export API_PREFIX=my_api\n</code></pre> <p>Note</p> <p>This variable is optional, so if it doesn't exist in <code>secrets.json</code>, the API will be accessible at <code>/api/</code> by default.</p>"},{"location":"quick-start/Advanced-options-for-deployment/#selected-engines-in-the-gui-indexhtml-only","title":"Selected engines in the GUI (<code>index.html</code> only)","text":"<p>In <code>secrets.json</code>:</p> <ul> <li>Adding <code>\"gui_enabled_engines\": [\"reverse_dns\", \"rdap_whois\"]</code> in <code>secrets.json</code> will restrict usage of these two engines in the GUI.</li> </ul> <p>Or using environment variables:</p> <pre><code>export GUI_ENABLED_ENGINES=reverse_dns,rdap_whois\n</code></pre> <p>Note</p> <p>This variable is optional, so if it doesn't exist in <code>secrets.json</code> or ENV, all engines will be displayed in the GUI.</p> <p>Tip</p> <p>Example: for the demo instance of cyberbro, only these engines are used: <code>\"gui_enabled_engines\": [\"reverse_dns\", \"rdap_whois\", \"ipquery\", \"abuseipdb\", \"virustotal\", \"spur\", \"google_safe_browsing\", \"shodan\", \"phishtank\", \"threatfox\", \"urlscan\", \"google\", \"github\", \"opencti\", \"abusix\", \"hudsonrock\"]</code> With environment variable: <code>GUI_ENABLED_ENGINES=reverse_dns,rdap_whois,ipquery,abuseipdb,virustotal,spur,google_safe_browsing,shodan,phishtank,threatfox,urlscan,google,github,opencti,abusix,hudsonrock</code></p>"},{"location":"quick-start/Advanced-options-for-deployment/#ssl-verification-settings-for-requests-backend","title":"SSL verification settings for requests (backend)","text":"<p>Danger</p> <p>This is really insecure to do disable it, do it at your own risk.</p> <p>You can change the default behavior using the following:</p> <p>In <code>secrets.json</code>:</p> <p>Adding <code>\"ssl_verify\": false</code> in <code>secrets.json</code> will disable the certificate trust verification in the requests (backend).</p> <p>Or using environment variables:</p> <pre><code>export SSL_VERIFY=false\n</code></pre> <p>Tip</p> <p>This variable is optional, so if it doesn't exist in <code>secrets.json</code> or ENV, it will use the default parameter (True) which is more secure.</p>"},{"location":"quick-start/Advanced-options-for-deployment/#config-page-in-the-gui-confightml-httpcyberbrolocal5000config","title":"Config page in the GUI (<code>config.html</code>) http://cyberbro.local:5000/config","text":"<p>Danger</p> <p>This is unsecure so it is disabled by default.</p> <p>You can add it using the following:</p> <p>In <code>secrets.json</code>:</p> <p>Adding <code>\"config_page_enabled\": true</code> in <code>secrets.json</code> will enable the config page in the GUI at http://cyberbro.local:5000/config</p> <p>Or using environment variables:</p> <pre><code>export CONFIG_PAGE_ENABLED=true\n</code></pre> <p>Note</p> <p>This variable is optional, so if it doesn't exist in <code>secrets.json</code> or ENV, it will be disabled by default.</p>"},{"location":"quick-start/Advanced-options-for-deployment/#upload-more-than-1mb-observables-in-the-form","title":"Upload more than 1MB observables in the form","text":"<p>By default, the form in the GUI only accepts 1MB of data. You can change this limit using the following: In <code>secrets.json</code>: Adding <code>\"max_form_memory_size\": 1048576</code> in <code>secrets.json</code> will set the limit to 1MB (1048576 bytes) in the form. Or using environment variables: <pre><code>export MAX_FORM_MEMORY_SIZE=1048576\n</code></pre></p> <p>Note</p> <p>The value must be set in bytes, so 1MB = 1048576 bytes, 2MB = 2097152 bytes, etc. Don't set it too high, it can cause problems with the database or treatment of the data. This variable is optional, so if it doesn't exist in <code>secrets.json</code> or ENV, it will use the default parameter (1MB).</p> <p>Flask doc about MAX_FORM_MEMORY_SIZE</p>"},{"location":"quick-start/Advanced-options-for-deployment/#cache-timeout-for-the-gui","title":"Cache timeout for the GUI","text":"<p>Note</p> <p>This is the timeout for the cache in the GUI, not the API. The default value is 1800 seconds (30 minutes). You can change this value using the following:</p> <p>In <code>secrets.json</code>: Adding <code>\"gui_cache_timeout\": 1800</code> in <code>secrets.json</code> will set the timeout to 30 minutes (1800 seconds) in the GUI. Or using environment variables: <pre><code>export GUI_CACHE_TIMEOUT=1800\n</code></pre></p> <p>Note</p> <p>The value must be set in seconds, so 1 minute = 60 seconds, 1 hour = 3600 seconds, etc. Don't set it too high, it can cause problems with the database or treatment of the data. This variable is optional, so if it doesn't exist in <code>secrets.json</code> or ENV, it will use the default parameter (30 minutes).</p>"},{"location":"quick-start/Advanced-options-for-deployment/#cache-timeout-for-the-api","title":"Cache timeout for the API","text":"<p>Note</p> <p>This is the timeout for the cache in the API, not the GUI. The default value is 86400 seconds (24 hours). You can change this value using the following:</p> <p>In <code>secrets.json</code>: Adding <code>\"api_cache_timeout\": 86400</code> in <code>secrets.json</code> will set the timeout to 24 hours (86400 seconds) in the API. Or using environment variables: <pre><code>export API_CACHE_TIMEOUT=86400\n</code></pre></p> <p>Note</p> <p>The value must be set in seconds, so 1 minute = 60 seconds, 1 hour = 3600 seconds, etc. Don't set it too high, it can cause problems with the database or treatment of the data. This variable is optional, so if it doesn't exist in <code>secrets.json</code> or ENV, it will use the default parameter (24 hours).</p>"},{"location":"quick-start/Quick-start-%26-Installation/","title":"Getting Started - TL;DR","text":"<p>Tip</p> <p>If you are lazy, you need Docker. Do a <code>git clone</code> ; copy <code>secrets-sample.json</code> to <code>secrets.json</code> ; <code>docker compose up</code> then go to <code>localhost:5000</code>. Yep, that's it!</p> docker compose versionDocker Compose version v2.5.0git clone https://github.com/stanfrbd/cyberbrocd cyberbrocp secrets-sample.json secrets.jsondocker compose up --build # use -d to run in backgroundGo to http://127.0.0.1:5000/"},{"location":"quick-start/Quick-start-%26-Installation/#getting-started","title":"Getting Started","text":"<ul> <li>To get started, clone the repository</li> </ul> <pre><code>git clone https://github.com/stanfrbd/cyberbro\ncd cyberbro\n</code></pre>"},{"location":"quick-start/Quick-start-%26-Installation/#edit-the-config-file-mandatory","title":"Edit the config file (mandatory)","text":"<pre><code>cp secrets-sample.json secrets.json\n</code></pre> <p>Note</p> <p>Don't have API keys? No problem\u2014just copy the <code>secrets-sample.json</code> to <code>secrets.json</code> and leave everything as is.</p> <p>Be careful if a proxy is used. You will be able to use all free engines!</p> <ul> <li>Fill values (including proxy if needed) in the <code>secrets.json</code> file.</li> </ul> <pre><code>{\n    \"abuseipdb\": \"token_here\",\n    \"alienvault\": \"token_here\",\n    \"criminalip_api_key\": \"token_here\",\n    \"crowdstrike_client_id\": \"client_id_here\",\n    \"crowdstrike_client_secret\": \"client_secret_here\",\n    \"dfir_iris_api_key\": \"token_here\",\n    \"dfir_iris_url\": \"https://dfir-iris.local\",\n    \"google_cse_cx\": \"cx_here\",\n    \"google_cse_key\": \"key_here\",\n    \"google_safe_browsing\": \"token_here\",\n    \"ipapi\": \"token_here\",\n    \"ipinfo\": \"token_here\",\n    \"mde_client_id\": \"client_id_here\",\n    \"mde_client_secret\": \"client_secret_here\",\n    \"mde_tenant_id\": \"tenant_here\",\n    \"misp_api_key\": \"token_here\",\n    \"misp_url\": \"https://misp.local\",\n    \"opencti_api_key\": \"token_here\",\n    \"opencti_url\": \"https://demo.opencti.io\",\n    \"proxy_url\": \"\",\n    \"rl_analyze_api_key\": \"token_here\",\n    \"rl_analyze_url\": \"https://spectra_analyse_url_here\",\n    \"rosti_api_key\": \"token_here\",\n    \"shodan\": \"token_here\",\n    \"spur_us\": \"token_here\",\n    \"threatfox\": \"token_here\",\n    \"virustotal\": \"token_here\",\n    \"webscout\": \"token_here\"\n}\n</code></pre> <ul> <li>Obtain API keys from the official documentation of each service.</li> <li>Microsoft Defender for Endpoint (MDE) is a paid service and can be skipped if you don't have an account (unchecked by default).</li> </ul> <p>Info</p> <p>You can modify the configuration via the GUI at http://127.0.0.1:5000/config. This endpoint is disabled by default for security reasons, as it is not protected. To enable it, set <code>\"config_page_enabled\":true</code> in <code>secrets.json</code> or use <code>CONFIG_PAGE_ENABLED=true</code> as environment variable. This is not recommended for public or team use, as it exposes your API keys.</p>"},{"location":"quick-start/Quick-start-%26-Installation/#launch-the-app","title":"Launch the app","text":""},{"location":"quick-start/Quick-start-%26-Installation/#lazy-and-easy-use-docker","title":"Lazy and easy - use docker","text":"<p>Warning</p> <p>Make sure you install the <code>compose</code> plugin as <code>docker compose</code> and not <code>docker-compose</code>.</p> <pre><code>docker compose up # use -d to run in background and use --build to rebuild the image\n</code></pre> <ul> <li>Go to http://127.0.0.1:5000 and Enjoy.</li> </ul> <p>Don't forget to edit the <code>secrets.json</code> before building the image.</p>"},{"location":"quick-start/Quick-start-%26-Installation/#using-the-docker-image-from-github-packages-and-a-custom-docker-compose-file","title":"Using the docker image from GitHub Packages and a custom <code>docker compose</code> file","text":"<ul> <li>See more in Advanced deployment options</li> </ul>"},{"location":"quick-start/Quick-start-%26-Installation/#the-old-way","title":"The old way","text":"<ul> <li>Clone the repository and install the requirements.</li> </ul> <p>You might want to create a <code>venv</code> before installing the dependencies.</p> <pre><code>pip install -r requirements.txt\n</code></pre> <ul> <li>Run the app with <code>gunicorn</code> (clean mode).</li> </ul> <pre><code>gunicorn -b 0.0.0.0:5000 app:app --timeout 120\n</code></pre> <ul> <li>Run the app with in development mode.</li> </ul> <pre><code>python3 app.py\n</code></pre> <p>Warning</p> <p><code>secrets.json</code> must be present according to the sample, before building image or launching.</p>"},{"location":"quick-start/Reload-secrets-and-configuration/","title":"Reload Secrets & Configuration","text":""},{"location":"quick-start/Reload-secrets-and-configuration/#with-docker","title":"With docker","text":""},{"location":"quick-start/Reload-secrets-and-configuration/#the-container-cyberbro-is-running","title":"The container cyberbro is running","text":"<ol> <li><code>docker exec -it cyberbro bash</code></li> <li><code>root@7b6e1c38676e:/app# nano secrets.json</code></li> <li><code>root@7b6e1c38676e:/app# service supervisor restart</code></li> <li><code>root@7b6e1c38676e:/app# exit</code></li> <li>Then go to http://127.0.0.1:5000 and use Cyberbro.</li> </ol>"},{"location":"quick-start/Reload-secrets-and-configuration/#the-container-cyberbro-is-not-running","title":"The container cyberbro is not running","text":"<ol> <li>Edit <code>secrets.json</code> / <code>.env</code> with the updated values.</li> <li><code>docker compose up --build --force-recreate -d</code></li> <li>Then go to http://127.0.0.1:5000 and use Cyberbro.</li> </ol>"},{"location":"quick-start/Reload-secrets-and-configuration/#without-docker","title":"Without docker","text":"<ol> <li>Edit <code>secrets.json</code> with the updated values.</li> <li>Restart your <code>gunicorn</code> instance or start <code>supervisord</code> e.g. <code>service supervisord restart</code></li> <li>Then go to http://127.0.0.1:5000 and use Cyberbro.</li> </ol>"},{"location":"quick-start/Upgrade-Cyberbro/","title":"With docker","text":""},{"location":"quick-start/Upgrade-Cyberbro/#using-the-git-repo","title":"Using the <code>git</code> repo","text":"<ul> <li>Go to your cyberbro directory (e.g. <code>/opt/cyberbro</code>).</li> <li><code>docker compose down</code> (optional)</li> <li><code>git pull</code></li> <li><code>docker compose build --no-cache</code> (optional)</li> <li><code>docker compose up --build --force-recreate -d</code></li> </ul> <p>Warning</p> <p>Be careful that your <code>secrets.json</code> / <code>.env</code> is up to date.</p>"},{"location":"quick-start/Upgrade-Cyberbro/#using-the-image-from-github-packages","title":"Using the image from GitHub packages","text":"<p>Info</p> <p>Assuming you already have a valid custom docker compose file using the image <code>ghcr.io/stanfrbd/cyberbro:latest</code></p> <ul> <li>Go to your cyberbro directory (e.g. <code>/opt/cyberbro</code>) where your custom <code>docker compose</code> file is located.</li> </ul> <pre><code>docker compose down # optional\ndocker-compose up -d --pull always --force-recreate\n</code></pre> <p>Warning</p> <p>Be careful that your environment variables / <code>.env</code> and your custom <code>docker compose</code> file are up to date.</p>"},{"location":"quick-start/Upgrade-Cyberbro/#without-docker","title":"Without docker","text":"<p>Info</p> <p>It is recommended to use <code>virtualenv</code> or <code>uv</code> to isolate the installation.</p> <ul> <li>Go to your cyberbro directory (e.g. <code>/opt/cyberbro</code>).</li> <li><code>git pull</code></li> <li><code>pip install -r requirements.txt</code></li> <li><code>rm data/version_cache.json</code></li> <li><code>gunicorn -b 0.0.0.0:5000 app:app --timeout 120</code> (or using <code>supervisord.conf</code>)</li> </ul> <p>Warning</p> <p>Be careful that your <code>secrets.json</code> is up to date</p>"},{"location":"troubleshooting/Common-Issues/","title":"Common Issues","text":"<p>Many questions and issues have already been addressed in the GitHub Issues tab. Please use the search bar to check if your question has already been answered.</p> <p>Most API-related questions or errors are due to misconfigurations. Make sure to carefully read the documentation and use the search function. If you find something missing, feel free to open a Pull Request to improve the docs.</p>"},{"location":"troubleshooting/Common-Issues/#opencti-and-misp-every-self-hosted-instance","title":"OpenCTI and MISP &amp; every self-hosted instance","text":"<p>For certificate issues, ensure the correct certificate is installed on your machine. Disabling SSL verification is possible but not recommended.</p>"},{"location":"troubleshooting/Common-Issues/#disabling-some-engines","title":"Disabling some engines","text":"<p>If you want to disable certain engines, make sure you set the correct variable as described here.</p>"},{"location":"troubleshooting/Common-Issues/#github-docker-image-errors","title":"GitHub Docker Image Errors","text":"<p>If you encounter errors with the GitHub Docker image, ensure you are authenticated to the GitHub Docker registry. Refer to the official documentation for guidance.</p>"},{"location":"troubleshooting/Common-Issues/#where-are-the-logs","title":"Where are the logs?","text":"<p>By default, logs generated by Cyberbro are stored inside the Docker container at <code>/var/log/cyberbro</code>, which is mapped to the <code>logs</code> directory in the Cyberbro folder on your host machine. However, you can configure the log storage location by adjusting the volume mapping in your Docker configuration.</p> <p>For example, in your <code>docker-compose-custom.yml</code>:</p> <pre><code>services:\n    web:\n        # ... other configuration ...\n        volumes:\n            - ./logs:/var/log/cyberbro\n</code></pre> <p>This configuration ensures that:</p> <ul> <li><code>./logs:/var/log/cyberbro</code>: Maps the <code>logs</code> directory on your host machine to <code>/var/log/cyberbro</code> inside the container. You can change <code>./logs</code> to any directory you prefer for storing logs.</li> </ul> <p>Note</p> <pre><code>Persisting logs is useful for troubleshooting and monitoring.  \nMake sure the `logs` directory exists on your host, or Docker will create it automatically.\n</code></pre> <p>For more details on volume mappings and other advanced deployment options, see the Advanced options for deployment documentation.</p>"},{"location":"troubleshooting/Common-Issues/#where-is-the-database","title":"Where is the database?","text":"<p>By default, the database used by Cyberbro is stored in the <code>data</code> directory inside the Docker container at <code>/app/data/results.db</code>, which is mapped to the <code>data</code> directory in the Cyberbro folder on your host machine. You can configure the database storage location by changing the volume mapping in your Docker configuration to point to a different directory if needed.</p>"},{"location":"troubleshooting/Common-Issues/#my-api-keys-seem-to-be-ignored-or-not-stored","title":"My API keys seem to be ignored or not stored","text":"<p>Danger</p> <p>Make sure you use either <code>secrets.json</code> or <code>.env</code> file for your deployment, not both. This may lead to unexpected behavior as the application will try to read both files and may override some values.</p>"}]}